{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## LALR testing for sBQC loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#My imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from adahessian import Adahessian, get_params_grad\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import math\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Other imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import auc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "# import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loss function code:\n",
    "\n",
    "def bareCDF(yhat, tau):\n",
    "    # yhat is a torch tensor, tau is a float\n",
    "    ind= (torch.sign(yhat)+1)/2 # mask about the origin\n",
    "    quantFactor= (1-tau)*ind + tau*(1-ind)\n",
    "    val= tau+4*quantFactor/math.pi*torch.atan(torch.tanh(yhat/2))\n",
    "    # print(\"bareCDF val: {}\".format(val))\n",
    "    return val\n",
    "\n",
    "def baresBQR(y, yhat, tau):\n",
    "    # y and yhat are torch tensors, tau is a float\n",
    "    val= torch.matmul(y,torch.log(1-bareCDF(yhat, tau)))+ torch.matmul((1-y),torch.log(bareCDF(yhat, tau)))\n",
    "    # print(\"bareBQR val: {}\".format(val))\n",
    "    return val\n",
    "\n",
    "class sBQRL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sBQRL, self).__init__()\n",
    "    \n",
    "    def forward(self, y, yhat, tau):\n",
    "        return baresBQR(y, yhat, tau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset= \"./Datasets/Classification/heart.csv\"\n",
    "x_cols = list(range(13)) # 13,8\n",
    "y_col = 13 # 13,8\n",
    "\n",
    "attribute_index = 7  # This controls which attribute is allowed to vary, 7,5\n",
    "attribute_name = \"BMI\" # Name of the attribute, used in the plots, max heart rate\n",
    "latent_name = \"Diabetes\" # Name of the function, used in the plots\n",
    "# The other attributes are replaced by the median value of the attribute\n",
    "Scaler= StandardScaler()\n",
    "batch_is= 64\n",
    "\n",
    "total_epochs = 20\n",
    "\n",
    "### \n",
    "def create_xy(dataset, attribute_columns, target_column, delim, split_ratio, ditch_head=True):\n",
    "    with open(dataset, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    if ditch_head:\n",
    "        lines = lines[1:]\n",
    "    X = []\n",
    "    Y = []\n",
    "    for line in lines:\n",
    "        while len(line) > 0 and line[-1] == \"\\n\":\n",
    "            line = line[:len(line)-1]\n",
    "        split_array = line.split(delim)\n",
    "        all_columns = []\n",
    "        for value in split_array:\n",
    "            if value !=\"\" and value !=\" \":\n",
    "                all_columns.append(value)\n",
    "        if len(all_columns)==0:\n",
    "            break\n",
    "        point = []\n",
    "        for i in attribute_columns:\n",
    "            point.append(float(all_columns[i]))\n",
    "        X.append(point)\n",
    "        Y.append(float(all_columns[target_column]))\n",
    "    X_arr = np.asarray(X)\n",
    "    X_unscaled = np.asarray(X)\n",
    "    Scaler.fit(X_arr)\n",
    "    X_arr = Scaler.transform(X_arr)\n",
    "    Y_arr = np.asarray(Y)\n",
    "    thresh = 0\n",
    "    Y_arr_binary = np.where(Y_arr<=thresh,0,1)\n",
    "    unique, counts = np.unique(Y_arr_binary, return_counts=True)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_arr, Y_arr_binary, test_size = split_ratio)\n",
    "    return x_train, x_test, y_train, y_test, Y_arr, X_arr, X_unscaled\n",
    "\n",
    "###\n",
    "X_train,X_val,y_train,y_val, data_Y, data_X_scaled, data_X_unscaled = create_xy(dataset, x_cols, y_col, \",\", 0.4)\n",
    "shap_x_train = X_train.copy()\n",
    "shap_x_val = X_val.copy()\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "# y_train= F.one_hot(y_train.to(torch.int64), num_classes=2)\n",
    "X_val = torch.Tensor(X_val)\n",
    "y_val = torch.Tensor(y_val)\n",
    "# y_val= F.one_hot(y_val.to(torch.int64), num_classes=2)\n",
    "train_dataset = data_utils.TensorDataset(X_train, y_train)\n",
    "test_dataset = data_utils.TensorDataset(X_val, y_val)\n",
    "train_loader = data_utils.DataLoader(train_dataset, batch_size =batch_is, pin_memory=True,shuffle=True,num_workers = 1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,batch_size =batch_is,pin_memory=True,shuffle = False,num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network definition:\n",
    "class LALRnetwork(nn.Module):\n",
    "    def __init__(self, indim):\n",
    "        super(LALRnetwork,self).__init__()\n",
    "        self.l1 = nn.Linear(indim,100)\n",
    "        self.l2 = nn.Linear(100,10)\n",
    "        self.l3 = nn.Linear(10,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.l1(x))\n",
    "        x = F.tanh(self.l2(x))\n",
    "        # x = F.softmax(self.l3(x))\n",
    "        x = F.sigmoid(self.l3(x))\n",
    "        # x= torch.sign(x-torch.ones_like(x)*0.5)\n",
    "        # x= (x+torch.ones_like(x))/2\n",
    "        return x\n",
    "    \n",
    "    # Used in LALR\n",
    "    def penU(self, x):\n",
    "        op = F.tanh(self.l1(x))\n",
    "        op = F.tanh(self.l2(op))\n",
    "        return op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Global initialisations:\n",
    "device= ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "indim = X_train.shape[1]\n",
    "modelLALR_sBQC = LALRnetwork(indim).to(device)\n",
    "modelCLR_sBQC= LALRnetwork(indim).to(device)\n",
    "modelLALR_BCE= LALRnetwork(indim).to(device)\n",
    "modelCLR_BCE= LALRnetwork(indim).to(device)\n",
    "modelLBFGS_sBQC = LALRnetwork(indim).to(device)\n",
    "\n",
    "criterion= sBQRL()\n",
    "criterion_= nn.BCELoss()\n",
    "h= 0.4\n",
    "lr_is = 1e-2\n",
    "optimizerLALR_sBQC= torch.optim.SGD(modelLALR_sBQC.parameters(), lr = lr_is)\n",
    "optimizerLALR_BCE= torch.optim.SGD(modelLALR_BCE.parameters(), lr = lr_is)\n",
    "optimizerCLR_sBQC= torch.optim.SGD(modelCLR_sBQC.parameters(), lr = lr_is)\n",
    "optimizerCLR_BCE= torch.optim.SGD(modelCLR_BCE.parameters(), lr = lr_is)\n",
    "optimizerLBFGS_sBQC= torch.optim.LBFGS(modelLBFGS_sBQC.parameters(), lr = lr_is)\n",
    "\n",
    "all_qs = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "all_qs = torch.Tensor(all_qs).to(device)\n",
    "mean_is = 0\n",
    "std_is = 1\n",
    "penalty = 1\n",
    "alpha = 0.0\n",
    "tau= 0.2\n",
    "\n",
    "ls_list_LALR_sBQC= []\n",
    "val_list_LALR_sBQC= []\n",
    "acc_list_LALR_sBQC= []\n",
    "ls_list_CLR_sBQC= []\n",
    "val_list_CLR_sBQC= []\n",
    "acc_list_CLR_sBQC= []\n",
    "ls_list_LALR_BCE= []\n",
    "val_list_LALR_BCE= []\n",
    "acc_list_LALR_BCE= []\n",
    "ls_list_CLR_BCE= []\n",
    "val_list_CLR_BCE= []\n",
    "acc_list_CLR_BCE= []\n",
    "\n",
    "ls_list_LBFGS_sBQC= []\n",
    "val_list_LBFGS_sBQC= []\n",
    "acc_list_LBFGS_sBQC= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training loops:\n",
    "def trainConstantLR(model, trainLoader, valLoader, optimizer, criterion, tau, epochs, ls_list, valList, acc_list, loss_name= \"sBQC\"):\n",
    "    \"\"\"\n",
    "    Training loop used for CLR training\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss= 0.0\n",
    "        # training loop\n",
    "        model.train()\n",
    "        for inputs, labels in trainLoader: \n",
    "            inputs= inputs.to(device) \n",
    "            labels= labels.to(device)\n",
    "            optimizer.zero_grad() \n",
    "            outputs= model(inputs) \n",
    "            # loss= criterion(torch.unsqueeze(labels, 1), outputs, tau) \n",
    "            # print(outputs, labels)\n",
    "            # outputs= outputs.to(torch.LongTensor()).to(device)\n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            # loss= criterion(outputs, labels) # works for one hot encoding and BCE\n",
    "            # loss= criterion(outputs, torch.unsqueeze(labels, 1))#, tau) \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            epoch_loss+= loss.item()\n",
    "        ls_list.append(epoch_loss/len(trainLoader))\n",
    "\n",
    "        # validation loop\n",
    "        val_loss= 0.0\n",
    "        num_correct= 0\n",
    "        total= 0 \n",
    "        model.eval()\n",
    "        for inputs, labels in valLoader:\n",
    "            inputs= inputs.to(device)\n",
    "            labels= labels.to(device)\n",
    "            outputs= model(inputs)\n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            val_loss+= loss.item()\n",
    "            x= torch.where(outputs.view(outputs.shape[0]) > 0.5, 1, 0)\n",
    "            num_correct += (x==labels).sum()\n",
    "            total += labels.size(0)\n",
    "        valList.append(val_loss/len(valLoader))\n",
    "        acc_list.append(float(num_correct)/float(total)*100)\n",
    "        print(\"Epoch: {} Training Loss: {} Validation loss: {} Accuracy: {}\".format(epoch, epoch_loss/len(trainLoader), val_loss/len(valLoader),\n",
    "         float(num_correct)/float(total)*100))\n",
    "\n",
    "\n",
    "def trainLALR(model, trainLoader, valLoader, optimizer, criterion, tau, epochs, ls_list, valList, acc_list, mask, loss_name= \"sBQC\"):\n",
    "    \"\"\"\n",
    "    Training loop used for LALR training\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss= 0.0\n",
    "        lr_val= computeLR(model,train_loader, mask, tau, bSize= batch_is)\n",
    "        optimizer.param_groups[0]['lr']= lr_val\n",
    "        # training loop\n",
    "        model.train()\n",
    "        for inputs, labels in trainLoader: \n",
    "            inputs= inputs.to(device) \n",
    "            labels= labels.to(device)\n",
    "            optimizer.zero_grad() \n",
    "            outputs= model(inputs) \n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            epoch_loss+= loss.item()\n",
    "        ls_list.append(epoch_loss/len(trainLoader))\n",
    "\n",
    "        # validation loop\n",
    "        val_loss= 0.0\n",
    "        num_correct= 0\n",
    "        total= 0 \n",
    "        model.eval()\n",
    "        for inputs, labels in valLoader:\n",
    "            inputs= inputs.to(device)\n",
    "            labels= labels.to(device)\n",
    "            outputs= model(inputs)\n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion_(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            val_loss+= loss.item()\n",
    "            x= torch.where(outputs.view(outputs.shape[0]) > 0.5, 1, 0)\n",
    "            num_correct += (x==labels).sum()\n",
    "            total += labels.size(0)\n",
    "        valList.append(val_loss/len(valLoader))\n",
    "        acc_list.append(float(num_correct)/float(total)*100)\n",
    "        print(\"Epoch: {} Training Loss: {} Validation loss: {} LR: {} Accuracy: {}\".format(epoch, epoch_loss/len(trainLoader), val_loss/len(valLoader), optimizer.param_groups[0]['lr'], float(num_correct)/float(total)*100))\n",
    "\n",
    "def trainLBFGS(model, trainLoader, valLoader, optimizer, criterion, tau, epochs, ls_list, valList, acc_list, loss_name= \"sBQC\"):\n",
    "    \"\"\"\n",
    "    Training loop used for LBFGS and conjugate gradient training\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss= 0.0\n",
    "        # training loop\n",
    "        model.train()\n",
    "        for inputs, labels in trainLoader: \n",
    "            inputs= inputs.to(device) \n",
    "            labels= labels.to(device)\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                outputs= model(inputs)\n",
    "                if loss_name== \"BCE\":\n",
    "                    loss= criterion(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "                elif loss_name== \"sBQC\":\n",
    "                    loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "                loss.backward()\n",
    "                return loss\n",
    "            # optimizer.step(closure)\n",
    "            # optimizer.zero_grad() \n",
    "            # outputs= model(inputs) \n",
    "            # loss= criterion(outputs, labels, tau, h) \n",
    "            # loss.backward()\n",
    "            optimizer.step(closure) \n",
    "        # ls_list.append(epoch_loss/len(trainLoader))\n",
    "\n",
    "        # validation loop\n",
    "        val_loss= 0.0\n",
    "        num_correct= 0\n",
    "        total= 0 \n",
    "        model.eval()\n",
    "        for inputs, labels in valLoader:\n",
    "            inputs= inputs.to(device)\n",
    "            labels= labels.to(device)\n",
    "            outputs= model(inputs)\n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            val_loss+= loss.item()\n",
    "            x= torch.where(outputs.view(outputs.shape[0]) > 0.5, 1, 0)\n",
    "            num_correct += (x==labels).sum()\n",
    "            total += labels.size(0)\n",
    "        valList.append(val_loss/len(valLoader))\n",
    "        acc_list.append(float(num_correct)/float(total)*100)\n",
    "        print(\"Epoch: {} Training Loss: {} Validation loss: {} Accuracy: {}\".format(epoch, epoch_loss/len(trainLoader), val_loss/len(valLoader),\n",
    "         float(num_correct)/float(total)*100))\n",
    "\n",
    "def computeLR(model, trainLoader, mask, tau, bSize= 16):\n",
    "    \"\"\"\n",
    "    Takes in a network of the LALRnetwork class(during some arbitrary EPOCH of training) and the current input, and returns Kz for the EPOCH\n",
    "    \"\"\"\n",
    "    Kz = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,j in enumerate(trainLoader):\n",
    "            inputs,labels= j[0],j[1]\n",
    "            inputs= inputs.to(device)\n",
    "            labels= labels.to(device)\n",
    "            op1= model.penU(inputs)\n",
    "            # first taking the max and min for each batch\n",
    "            activ1, indx1= torch.max(op1, dim= 1)\n",
    "            # now, we take the max and min across batches\n",
    "            val1, indx2= torch.max(activ1, dim= 0)\n",
    "            # print(indx, i)\n",
    "            if val1 > Kz:\n",
    "                # in the case of K_z, we do not need the index where the max occurs, hence only deal with the value\n",
    "                Kz= val1 \n",
    "    factor= 1\n",
    "    if mask == 1:\n",
    "        factor =  max(2/math.pi, 2-2*tau/(math.pi*tau), 2*tau/(math.pi*(1-tau)))\n",
    "    else:\n",
    "        factor= 0.5\n",
    "    LR= (factor*Kz)/bSize\n",
    "    # if LR == 0:\n",
    "    #     return 0.1\n",
    "    return (1/LR)*0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: -48.034890492757164 Validation loss: -63.3626823425293 LR: 0.060971055179834366 Accuracy: 80.32786885245902\n",
      "Epoch: 1 Training Loss: -65.2692642211914 Validation loss: -65.9653434753418 LR: 0.04717822000384331 Accuracy: 83.60655737704919\n",
      "Epoch: 2 Training Loss: -67.4573262532552 Validation loss: -66.65286254882812 LR: 0.04696933552622795 Accuracy: 82.78688524590164\n",
      "Epoch: 3 Training Loss: -67.82853825887044 Validation loss: -67.13041305541992 LR: 0.04695512726902962 Accuracy: 83.60655737704919\n",
      "Epoch: 4 Training Loss: -67.81335703531902 Validation loss: -67.16574668884277 LR: 0.04694550111889839 Accuracy: 80.32786885245902\n",
      "Epoch: 5 Training Loss: -68.93311309814453 Validation loss: -67.7679214477539 LR: 0.046943873167037964 Accuracy: 82.78688524590164\n",
      "Epoch: 6 Training Loss: -68.85675938924153 Validation loss: -66.85663604736328 LR: 0.046942975372076035 Accuracy: 81.9672131147541\n",
      "Epoch: 7 Training Loss: -69.37136967976888 Validation loss: -66.94118881225586 LR: 0.046942517161369324 Accuracy: 81.14754098360656\n",
      "Epoch: 8 Training Loss: -69.80124155680339 Validation loss: -66.8886489868164 LR: 0.04694231599569321 Accuracy: 82.78688524590164\n",
      "Epoch: 9 Training Loss: -69.94730377197266 Validation loss: -67.00276184082031 LR: 0.04694228246808052 Accuracy: 83.60655737704919\n"
     ]
    }
   ],
   "source": [
    "# LALR, sBQC\n",
    "trainLALR(modelLALR_sBQC, train_loader, test_loader, optimizerLALR_sBQC, criterion, tau, 10, ls_list_LALR_sBQC, val_list_LALR_sBQC, acc_list_LALR_sBQC, 1, \"sBQC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 0.6701245903968811 Validation loss: 0.6411528885364532 LR: 0.16850508749485016 Accuracy: 68.0327868852459\n",
      "Epoch: 1 Training Loss: 0.6273759007453918 Validation loss: 0.6038942933082581 LR: 0.16393183171749115 Accuracy: 75.40983606557377\n",
      "Epoch: 2 Training Loss: 0.5884689887364706 Validation loss: 0.5686658322811127 LR: 0.15039604902267456 Accuracy: 77.8688524590164\n",
      "Epoch: 3 Training Loss: 0.5494326949119568 Validation loss: 0.5361926853656769 LR: 0.14320386946201324 Accuracy: 78.68852459016394\n",
      "Epoch: 4 Training Loss: 0.5141144692897797 Validation loss: 0.5064030289649963 LR: 0.13894619047641754 Accuracy: 80.32786885245902\n",
      "Epoch: 5 Training Loss: 0.48473841945330304 Validation loss: 0.4812197834253311 LR: 0.13643237948417664 Accuracy: 80.32786885245902\n",
      "Epoch: 6 Training Loss: 0.45609330137570697 Validation loss: 0.46019382774829865 LR: 0.13476215302944183 Accuracy: 79.50819672131148\n",
      "Epoch: 7 Training Loss: 0.4334932168324788 Validation loss: 0.44329284131526947 LR: 0.13356934487819672 Accuracy: 81.14754098360656\n",
      "Epoch: 8 Training Loss: 0.40960567196210224 Validation loss: 0.42969587445259094 LR: 0.1328500360250473 Accuracy: 81.14754098360656\n",
      "Epoch: 9 Training Loss: 0.39559853076934814 Validation loss: 0.4194386303424835 LR: 0.13224577903747559 Accuracy: 81.14754098360656\n"
     ]
    }
   ],
   "source": [
    "# LALR, BCE\n",
    "trainLALR(modelLALR_BCE, train_loader, test_loader, optimizerLALR_BCE, criterion_, tau, 10, ls_list_LALR_BCE, val_list_LALR_BCE, acc_list_LALR_BCE, 2, \"BCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: -70.02423985799153 Validation loss: -66.75816345214844 Accuracy: 80.32786885245902\n",
      "Epoch: 1 Training Loss: -70.13212331136067 Validation loss: -66.79656219482422 Accuracy: 80.32786885245902\n",
      "Epoch: 2 Training Loss: -70.15995407104492 Validation loss: -66.81208419799805 Accuracy: 80.32786885245902\n",
      "Epoch: 3 Training Loss: -70.28599294026692 Validation loss: -66.81711196899414 Accuracy: 80.32786885245902\n",
      "Epoch: 4 Training Loss: -70.30209986368816 Validation loss: -66.78569793701172 Accuracy: 80.32786885245902\n",
      "Epoch: 5 Training Loss: -70.38063557942708 Validation loss: -66.77813720703125 Accuracy: 80.32786885245902\n",
      "Epoch: 6 Training Loss: -70.40774027506511 Validation loss: -66.78976821899414 Accuracy: 80.32786885245902\n",
      "Epoch: 7 Training Loss: -70.47462844848633 Validation loss: -66.76856231689453 Accuracy: 80.32786885245902\n",
      "Epoch: 8 Training Loss: -70.5148188273112 Validation loss: -66.83937454223633 Accuracy: 80.32786885245902\n",
      "Epoch: 9 Training Loss: -70.55848566691081 Validation loss: -66.84365844726562 Accuracy: 80.32786885245902\n"
     ]
    }
   ],
   "source": [
    "# CLR, sBQC\n",
    "trainConstantLR(modelCLR_sBQC, train_loader, test_loader, optimizerCLR_sBQC, criterion, tau, 10, ls_list_CLR_sBQC, val_list_CLR_sBQC, acc_list_CLR_sBQC, \"sBQC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 0.6907435258229574 Validation loss: 0.6896280348300934 Accuracy: 50.0\n",
      "Epoch: 1 Training Loss: 0.6850954492886862 Validation loss: 0.6846938133239746 Accuracy: 54.09836065573771\n",
      "Epoch: 2 Training Loss: 0.678990364074707 Validation loss: 0.6798910796642303 Accuracy: 54.91803278688525\n",
      "Epoch: 3 Training Loss: 0.6743672688802084 Validation loss: 0.6751616895198822 Accuracy: 57.377049180327866\n",
      "Epoch: 4 Training Loss: 0.6690641244252523 Validation loss: 0.6705153286457062 Accuracy: 62.295081967213115\n",
      "Epoch: 5 Training Loss: 0.6646490097045898 Validation loss: 0.6659351885318756 Accuracy: 64.75409836065575\n",
      "Epoch: 6 Training Loss: 0.6605125864346822 Validation loss: 0.6614405512809753 Accuracy: 66.39344262295081\n",
      "Epoch: 7 Training Loss: 0.6562609473864237 Validation loss: 0.6570298671722412 Accuracy: 68.85245901639344\n",
      "Epoch: 8 Training Loss: 0.6511433919270834 Validation loss: 0.6527410745620728 Accuracy: 72.1311475409836\n",
      "Epoch: 9 Training Loss: 0.6469916502634684 Validation loss: 0.6485454440116882 Accuracy: 72.95081967213115\n"
     ]
    }
   ],
   "source": [
    "# CLR, BCE\n",
    "trainConstantLR(modelCLR_BCE, train_loader, test_loader, optimizerCLR_BCE, criterion_, tau, 10, ls_list_CLR_BCE, val_list_CLR_BCE, acc_list_CLR_BCE, \"BCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 1 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 2 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 3 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 4 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 5 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 6 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 7 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 8 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 9 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n"
     ]
    }
   ],
   "source": [
    "# LBFGS, sBQC\n",
    "trainLBFGS(modelLBFGS_sBQC, train_loader, test_loader, optimizerLBFGS_sBQC, criterion, tau, 10, ls_list_LBFGS_sBQC, val_list_LBFGS_sBQC, acc_list_LBFGS_sBQC, \"sBQC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1d7fa92450>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# error plots\n",
    "# plt.plot(range(10), ls_list_LALR_sBQC)\n",
    "# plt.plot(range(len(val_list_LALR_sBQC)), val_list_LALR_sBQC, label= \"LALR_sBQC\")\n",
    "# plt.plot(range(len(ls_list_LALR_sBQC)), ls_list_LALR_sBQC, label= \"LALR_sBQC_ls\")\n",
    "# plt.plot(range(len(val_list_CLR_sBQC)), val_list_CLR_sBQC, label= \"CLR_sBQC\")\n",
    "# plt.plot(range(len(val_list_LALR_sBQC)), val_list_LALR_BCE, label= \"LALR_BCE\")\n",
    "# plt.plot(range(len(val_list_CLR_sBQC)), val_list_CLR_BCE, label= \"CLR_BCE\")\n",
    "# plt.plot(range(len(acc_list_CLR_BCE)), acc_list_CLR_BCE, label= \"CLR_BCE_acc\")\n",
    "plt.plot(range(len(acc_list_CLR_sBQC)), acc_list_CLR_sBQC, label= \"CLR_sBQC_acc\")\n",
    "# plt.plot(range(len(acc_list_LALR_BCE)), acc_list_LALR_BCE, label= \"LALR_BCE_acc\")\n",
    "# plt.plot(range(len(acc_list_LALR_sBQC)), acc_list_LALR_sBQC, label= \"LALR_sBQC_acc\")\n",
    "# plt.plot(range(len(val_list_LBFGS_sBQC)), val_list_LBFGS_sBQC, label= \"LBFGS_sBQC_val\")\n",
    "plt.plot(range(len(acc_list_LBFGS_sBQC)), acc_list_LBFGS_sBQC, label= \"LBFGS_sBQC_acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# metrics:\n",
    "def computeMetrics(model):\n",
    "    outputs= torch.Tensor([])\n",
    "    outputs= outputs.to(device)\n",
    "    labels= torch.Tensor([])\n",
    "    labels= labels.to(device)\n",
    "    for inputs, label in test_loader:\n",
    "        inputs= inputs.to(device)\n",
    "        label= label.to(device)\n",
    "        output= model(inputs)\n",
    "        outputs= torch.cat((outputs, output))\n",
    "        labels= torch.cat((labels, label))\n",
    "    x= outputs\n",
    "    x= torch.where(outputs.view(outputs.shape[0]) > 0.5, 1, 0)\n",
    "    CP= cohen_kappa_score(labels.detach().to('cpu').numpy(), x.detach().to('cpu').numpy())\n",
    "    JS= jaccard_score(labels.detach().to('cpu').numpy(), x.detach().to('cpu').numpy())\n",
    "    F1= f1_score(labels.detach().to('cpu').numpy(), x.detach().to('cpu').numpy())\n",
    "    return [CP, JS, F1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6870105320010802, 0.75, 0.857142857142857]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeMetrics(modelLALR_BCE)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "argv": [
    "/home/aryamanj/miniconda3/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "name": "LALRclassification.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
