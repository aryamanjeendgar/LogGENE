{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import UCI_loader\n",
    "import importlib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# network class\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, indim, outdim):\n",
    "        super(Network,self).__init__()\n",
    "        self.l1 = nn.Linear(indim,100)\n",
    "        self.l2 = nn.Linear(100,50)\n",
    "        self.l3 = nn.Linear(50,outdim) \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = self.l3(x)\n",
    "        return x\n",
    "\n",
    "def tiltedLC(x, y, tau, h):\n",
    "    e= y-x # errors\n",
    "    ind= (torch.sign(e)+1)/2 # the division in the log-cosh is only about the origin\n",
    "    quantFactor= (1-tau)*(1-ind) + tau*ind\n",
    "    loss= quantFactor*torch.log(torch.cosh(e/h))\n",
    "    loss= torch.mean(loss)*h\n",
    "    return loss\n",
    "\n",
    "def check_loss(x, y, tau): # the x,*args way to pass arguments to this function is an idiom for the scipy.optimize() library y = args[0][0]\n",
    "    e = y-x\n",
    "    ind = (torch.sign(-e)+1)/2\n",
    "    loss = torch.mean(e*(tau-ind))\n",
    "    return loss\n",
    "\n",
    "class TiltedLC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TiltedLC, self).__init__()\n",
    "    def forward(self, x, y, tau, h):\n",
    "        return tiltedLC(x, y, tau, h)\n",
    "\n",
    "\n",
    "class CheckLC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CheckLC, self).__init__()\n",
    "    def forward(self, x, y, tau):\n",
    "        return check_loss(x, y, tau)\n",
    "\n",
    "# Getting the data\n",
    "importlib.reload(UCI_loader)\n",
    "data_energy= UCI_loader.UCIDatasets(\"energy\") \n",
    "data_yacht= UCI_loader.UCIDatasets(\"yacht\") \n",
    "train_data_energy= data_energy.get_split()\n",
    "train_data_yacht= data_yacht.get_split()\n",
    "# test_data= data.get_split(train=False)\n",
    "\n",
    "\n",
    "# instantiating the network for training on this dataset\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model11= Network(indim=8,outdim=2).to(device=device)\n",
    "model12= Network(indim=8,outdim=2).to(device=device)\n",
    "model21= Network(indim=6,outdim=1).to(device=device)\n",
    "model22= Network(indim=6,outdim=1).to(device=device)\n",
    "tau= 0.5\n",
    "h= 0.05\n",
    "\n",
    "criterion1= TiltedLC()\n",
    "criterion2= CheckLC()\n",
    "optimizer11= optim.Adam(model11.parameters())\n",
    "optimizer12= optim.Adam(model12.parameters())\n",
    "optimizer21= optim.Adam(model21.parameters())\n",
    "optimizer22= optim.Adam(model22.parameters())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# training using the log-cosh\n",
    "# the fundamental training loop\n",
    " # instantiating the DataLoader\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "                    train_data_energy,\n",
    "                    batch_size=16,\n",
    "                    shuffle=True)\n",
    "ls_a= []\n",
    "N_EPOCHS= 100\n",
    "for epoch in range(N_EPOCHS):\n",
    "    epoch_loss1 = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device)\n",
    "        optimizer11.zero_grad() \n",
    "        outputs = model11(inputs) \n",
    "        loss1= criterion1(outputs, labels, tau, h) \n",
    "        loss1.backward() \n",
    "        optimizer11.step() \n",
    "        epoch_loss1+= loss1.item() \n",
    "    ls_a.append((epoch_loss1/len(trainloader)))\n",
    "    print(\"Epoch: {} Loss: {}\".format(epoch,\n",
    "           epoch_loss1/len(trainloader)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# training using the check\n",
    "ls_b= []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    epoch_loss2 = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device)\n",
    "        optimizer12.zero_grad() \n",
    "        outputs = model12(inputs) \n",
    "        loss2= criterion2(outputs, labels, tau)\n",
    "        loss2.backward() \n",
    "        optimizer12.step() \n",
    "        epoch_loss2+= loss2.item() \n",
    "    ls_b.append(epoch_loss2/len(trainloader))\n",
    "    print(\"Epoch: {} Loss: {}\".format(epoch,\n",
    "           epoch_loss2/len(trainloader)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(range(N_EPOCHS), ls_a) # log-cosh\n",
    "plt.plot(range(N_EPOCHS), ls_b) # check"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "op_1= []\n",
    "op_2= []\n",
    "\n",
    "# creating an iterable through each element of the dataset\n",
    "pltLoad= torch.utils.data.DataLoader(\n",
    "                    train_data_energy,\n",
    "                    batch_size=1,\n",
    "                    shuffle=True)\n",
    "\n",
    "for inputs, labels in pltLoad:\n",
    "    inputs = inputs.to(device) \n",
    "    labels = labels.to(device)\n",
    "    outputs1 = model11(inputs) \n",
    "    outputs2= model12(inputs)\n",
    "    op_1.append(outputs1[0][0])\n",
    "    op_2.append(outputs2[0][0])\n",
    "\n",
    "plt.plot(range(len(pltLoad)), op_1) # plot of one of the responses for the log-cosh  \n",
    "plt.plot(range(len(pltLoad)), op_2) # plot of one of the responses for the check"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "6aac0f8b59c440fe53209fa4fafabace38fed25a653401172dea19fc00731209"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}