{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LALR testing for sBQC loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from adahessian import Adahessian, get_params_grad\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import math\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Other imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import auc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "# import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function code:\n",
    "\n",
    "def bareCDF(yhat, tau):\n",
    "    # yhat is a torch tensor, tau is a float\n",
    "    ind= (torch.sign(yhat)+1)/2 # mask about the origin\n",
    "    quantFactor= (1-tau)*ind + tau*(1-ind)\n",
    "    val= tau+4*quantFactor/math.pi*torch.atan(torch.tanh(yhat/2))\n",
    "    # print(\"bareCDF val: {}\".format(val))\n",
    "    return val\n",
    "\n",
    "def baresBQR(y, yhat, tau):\n",
    "    # y and yhat are torch tensors, tau is a float\n",
    "    test= bareCDF(yhat, tau)\n",
    "    val= y*torch.log(1-bareCDF(yhat, tau))+(1-y)*torch.log(bareCDF(yhat, tau))\n",
    "    # print(\"bareBQR val: {}\".format(val))\n",
    "    return val\n",
    "\n",
    "class sBQRL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sBQRL, self).__init__()\n",
    "    \n",
    "    def forward(self, y, yhat, tau):\n",
    "        return torch.mean(baresBQR(y, yhat, tau))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data code:\n",
    "dataset= \"./Datasets/Classification/pima.csv\"\n",
    "x_cols = list(range(8)) # 13,8\n",
    "y_col = 8 # 13,8\n",
    "\n",
    "attribute_index = 5  # This controls which attribute is allowed to vary, 7,5\n",
    "attribute_name = \"BMI\" # Name of the attribute, used in the plots, max heart rate\n",
    "latent_name = \"Diabetes\" # Name of the function, used in the plots\n",
    "# The other attributes are replaced by the median value of the attribute\n",
    "Scaler= StandardScaler()\n",
    "batch_is= 64\n",
    "\n",
    "total_epochs = 20\n",
    "\n",
    "### \n",
    "def create_xy(dataset, attribute_columns, target_column, delim, split_ratio, ditch_head=True):\n",
    "    with open(dataset, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    if ditch_head:\n",
    "        lines = lines[1:]\n",
    "    X = []\n",
    "    Y = []\n",
    "    for line in lines:\n",
    "        while len(line) > 0 and line[-1] == \"\\n\":\n",
    "            line = line[:len(line)-1]\n",
    "        split_array = line.split(delim)\n",
    "        all_columns = []\n",
    "        for value in split_array:\n",
    "            if value !=\"\" and value !=\" \":\n",
    "                all_columns.append(value)\n",
    "        if len(all_columns)==0:\n",
    "            break\n",
    "        point = []\n",
    "        for i in attribute_columns:\n",
    "            point.append(float(all_columns[i]))\n",
    "        X.append(point)\n",
    "        Y.append(float(all_columns[target_column]))\n",
    "    X_arr = np.asarray(X)\n",
    "    X_unscaled = np.asarray(X)\n",
    "    Scaler.fit(X_arr)\n",
    "    X_arr = Scaler.transform(X_arr)\n",
    "    Y_arr = np.asarray(Y)\n",
    "    thresh = 0\n",
    "    Y_arr_binary = np.where(Y_arr<=thresh,0,1)\n",
    "    unique, counts = np.unique(Y_arr_binary, return_counts=True)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_arr, Y_arr_binary, test_size = split_ratio)\n",
    "    return x_train, x_test, y_train, y_test, Y_arr, X_arr, X_unscaled\n",
    "\n",
    "###\n",
    "X_train,X_val,y_train,y_val, data_Y, data_X_scaled, data_X_unscaled = create_xy(dataset, x_cols, y_col, \",\", 0.4)\n",
    "shap_x_train = X_train.copy()\n",
    "shap_x_val = X_val.copy()\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "# y_train= F.one_hot(y_train.to(torch.int64), num_classes=2)\n",
    "X_val = torch.Tensor(X_val)\n",
    "y_val = torch.Tensor(y_val)\n",
    "# y_val= F.one_hot(y_val.to(torch.int64), num_classes=2)\n",
    "train_dataset = data_utils.TensorDataset(X_train, y_train)\n",
    "test_dataset = data_utils.TensorDataset(X_val, y_val)\n",
    "train_loader = data_utils.DataLoader(train_dataset, batch_size =batch_is, pin_memory=True,shuffle=True,num_workers = 1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,batch_size =batch_is,pin_memory=True,shuffle = False,num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network definition:\n",
    "class LALRnetwork(nn.Module):\n",
    "    def __init__(self, indim):\n",
    "        super(LALRnetwork,self).__init__()\n",
    "        self.l1 = nn.Linear(indim,100)\n",
    "        self.l2 = nn.Linear(100,10)\n",
    "        self.l3 = nn.Linear(10,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.l1(x))\n",
    "        x = F.tanh(self.l2(x))\n",
    "        # x = F.softmax(self.l3(x))\n",
    "        x = F.sigmoid(self.l3(x))\n",
    "        # x= torch.sign(x-torch.ones_like(x)*0.5)\n",
    "        # x= (x+torch.ones_like(x))/2\n",
    "        return x\n",
    "    \n",
    "    # Used in LALR\n",
    "    def penU(self, x):\n",
    "        op = F.tanh(self.l1(x))\n",
    "        op = F.tanh(self.l2(op))\n",
    "        return op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global initialisations:\n",
    "device= ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "indim = X_train.shape[1]\n",
    "modelLALR_sBQC = LALRnetwork(indim).to(device)\n",
    "modelCLR_sBQC= LALRnetwork(indim).to(device)\n",
    "modelLALR_BCE= LALRnetwork(indim).to(device)\n",
    "modelCLR_BCE= LALRnetwork(indim).to(device)\n",
    "criterion= sBQRL()\n",
    "criterion_= nn.BCELoss()\n",
    "h= 0.4\n",
    "lr_is = 1e-2\n",
    "optimizerLALR_sBQC= torch.optim.SGD(modelLALR_sBQC.parameters(), lr = lr_is)\n",
    "optimizerLALR_BCE= torch.optim.SGD(modelLALR_BCE.parameters(), lr = lr_is)\n",
    "optimizerCLR_sBQC= torch.optim.SGD(modelCLR_sBQC.parameters(), lr = lr_is)\n",
    "optimizerCLR_BCE= torch.optim.SGD(modelCLR_BCE.parameters(), lr = lr_is)\n",
    "\n",
    "all_qs = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "all_qs = torch.Tensor(all_qs).to(device)\n",
    "mean_is = 0\n",
    "std_is = 1\n",
    "penalty = 1\n",
    "alpha = 0.0\n",
    "tau= 0.2\n",
    "\n",
    "ls_list_LALR_sBQC= []\n",
    "val_list_LALR_sBQC= []\n",
    "acc_list_LALR_sBQC= []\n",
    "ls_list_CLR_sBQC= []\n",
    "val_list_CLR_sBQC= []\n",
    "acc_list_CLR_sBQC= []\n",
    "ls_list_LALR_BCE= []\n",
    "val_list_LALR_BCE= []\n",
    "acc_list_LALR_BCE= []\n",
    "ls_list_CLR_BCE= []\n",
    "val_list_CLR_BCE= []\n",
    "acc_list_CLR_BCE= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loops:\n",
    "def trainConstantLR(model, trainLoader, valLoader, optimizer, criterion, tau, epochs, ls_list, valList, acc_list, loss_name= \"sBQC\"):\n",
    "    \"\"\"\n",
    "    Training loop used for CLR training\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss= 0.0\n",
    "        # training loop\n",
    "        model.train()\n",
    "        for inputs, labels in trainLoader: \n",
    "            inputs= inputs.to(device) \n",
    "            labels= labels.to(device)\n",
    "            optimizer.zero_grad() \n",
    "            outputs= model(inputs) \n",
    "            # loss= criterion(torch.unsqueeze(labels, 1), outputs, tau) \n",
    "            # print(outputs, labels)\n",
    "            # outputs= outputs.to(torch.LongTensor()).to(device)\n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            # loss= criterion(outputs, labels) # works for one hot encoding and BCE\n",
    "            # loss= criterion(outputs, torch.unsqueeze(labels, 1))#, tau) \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            epoch_loss+= loss.item()\n",
    "        ls_list.append(epoch_loss/len(trainLoader))\n",
    "\n",
    "        # validation loop\n",
    "        val_loss= 0.0\n",
    "        num_correct= 0\n",
    "        total= 0 \n",
    "        model.eval()\n",
    "        for inputs, labels in valLoader:\n",
    "            inputs= inputs.to(device)\n",
    "            labels= labels.to(device)\n",
    "            outputs= model(inputs)\n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            val_loss+= loss.item()\n",
    "            x= torch.where(outputs.view(outputs.shape[0]) > 0.5, 1, 0)\n",
    "            # x= outputs\n",
    "            # x= torch.sign(x-torch.ones_like(x)*0.5)\n",
    "            # x= (x+torch.ones_like(x))/2\n",
    "            # print(x==labels)\n",
    "            num_correct += (x==labels).sum()\n",
    "            total += labels.size(0)\n",
    "        valList.append(val_loss/len(valLoader))\n",
    "        acc_list.append(float(num_correct)/float(total)*100)\n",
    "        print(\"Epoch: {} Training Loss: {} Validation loss: {} Accuracy: {}\".format(epoch, epoch_loss/len(trainLoader), val_loss/len(valLoader),\n",
    "         float(num_correct)/float(total)*100))\n",
    "\n",
    "\n",
    "def trainLALR(model, trainLoader, valLoader, optimizer, criterion, tau, epochs, ls_list, valList, acc_list, mask, loss_name= \"sBQC\"):\n",
    "    \"\"\"\n",
    "    Training loop used for LALR training\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss= 0.0\n",
    "        lr_val= computeLR(model,train_loader, mask, tau, bSize= batch_is)\n",
    "        optimizer.param_groups[0]['lr']= lr_val\n",
    "        # training loop\n",
    "        model.train()\n",
    "        for inputs, labels in trainLoader: \n",
    "            inputs= inputs.to(device) \n",
    "            labels= labels.to(device)\n",
    "            optimizer.zero_grad() \n",
    "            outputs= model(inputs) \n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            epoch_loss+= loss.item()\n",
    "        ls_list.append(epoch_loss/len(trainLoader))\n",
    "\n",
    "        # validation loop\n",
    "        val_loss= 0.0\n",
    "        num_correct= 0\n",
    "        total= 0 \n",
    "        model.eval()\n",
    "        for inputs, labels in valLoader:\n",
    "            inputs= inputs.to(device)\n",
    "            labels= labels.to(device)\n",
    "            outputs= model(inputs)\n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion_(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            val_loss+= loss.item()\n",
    "            x= torch.where(outputs.view(outputs.shape[0]) > 0.5, 1, 0)\n",
    "            num_correct += (x==labels).sum()\n",
    "            total += labels.size(0)\n",
    "        valList.append(val_loss/len(valLoader))\n",
    "        acc_list.append(float(num_correct)/float(total)*100)\n",
    "        print(\"Epoch: {} Training Loss: {} Validation loss: {} LR: {} Accuracy: {}\".format(epoch, epoch_loss/len(trainLoader), val_loss/len(valLoader), optimizer.param_groups[0]['lr'], float(num_correct)/float(total)*100))\n",
    "\n",
    "def computeLR(model, trainLoader, mask, tau, bSize= 16):\n",
    "    \"\"\"\n",
    "    Takes in a network of the LALRnetwork class(during some arbitrary EPOCH of training) and the current input, and returns Kz for the EPOCH\n",
    "    \"\"\"\n",
    "    Kz = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,j in enumerate(trainLoader):\n",
    "            inputs,labels= j[0],j[1]\n",
    "            inputs= inputs.to(device)\n",
    "            labels= labels.to(device)\n",
    "            op1= model.penU(inputs)\n",
    "            # first taking the max and min for each batch\n",
    "            activ1, indx1= torch.max(op1, dim= 1)\n",
    "            # now, we take the max and min across batches\n",
    "            val1, indx2= torch.max(activ1, dim= 0)\n",
    "            # print(indx, i)\n",
    "            if val1 > Kz:\n",
    "                # in the case of K_z, we do not need the index where the max occurs, hence only deal with the value\n",
    "                Kz= val1 \n",
    "    factor= 1\n",
    "    if mask == 1:\n",
    "        factor =  max(2/math.pi, 2-2*tau/(math.pi*tau))#, 2*tau/(math.pi*(1-tau)))\n",
    "    else:\n",
    "        factor= 0.5\n",
    "    LR= (factor*Kz)/bSize\n",
    "    # if LR == 0:\n",
    "    #     return 0.1\n",
    "    return (1/LR)*0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: -1.1355736404657364 Validation loss: -1.1529963970184327 LR: 0.04724797233939171 Accuracy: 75.0\n",
      "Epoch: 1 Training Loss: -1.1573114842176437 Validation loss: -1.1543177127838136 LR: 0.04723072052001953 Accuracy: 75.0\n",
      "Epoch: 2 Training Loss: -1.1704892665147781 Validation loss: -1.1552638053894042 LR: 0.04721257463097572 Accuracy: 74.67532467532467\n",
      "Epoch: 3 Training Loss: -1.1688228994607925 Validation loss: -1.1562403440475464 LR: 0.04719875380396843 Accuracy: 74.67532467532467\n",
      "Epoch: 4 Training Loss: -1.1688319593667984 Validation loss: -1.1567120790481566 LR: 0.04718543961644173 Accuracy: 74.67532467532467\n",
      "Epoch: 5 Training Loss: -1.1333882883191109 Validation loss: -1.1576577186584474 LR: 0.04717012122273445 Accuracy: 74.67532467532467\n",
      "Epoch: 6 Training Loss: -1.1373347714543343 Validation loss: -1.1590315341949462 LR: 0.04715796560049057 Accuracy: 74.67532467532467\n",
      "Epoch: 7 Training Loss: -1.1541241854429245 Validation loss: -1.1603663682937622 LR: 0.04714595153927803 Accuracy: 74.67532467532467\n",
      "Epoch: 8 Training Loss: -1.1421283036470413 Validation loss: -1.1616563081741333 LR: 0.04713338986039162 Accuracy: 75.0\n",
      "Epoch: 9 Training Loss: -1.152942255139351 Validation loss: -1.1624609708786011 LR: 0.04712199792265892 Accuracy: 75.0\n"
     ]
    }
   ],
   "source": [
    "# LALR, sBQC\n",
    "trainLALR(modelLALR_sBQC, train_loader, test_loader, optimizerLALR_sBQC, criterion, tau, 10, ls_list_LALR_sBQC, val_list_LALR_sBQC, acc_list_LALR_sBQC, 1, \"sBQC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 0.4746115244925022 Validation loss: 0.42679556012153624 LR: 0.132788747549057 Accuracy: 81.4935064935065\n",
      "Epoch: 1 Training Loss: 0.516699779778719 Validation loss: 0.42954443097114564 LR: 0.13159477710723877 Accuracy: 81.16883116883116\n",
      "Epoch: 2 Training Loss: 0.4932515285909176 Validation loss: 0.42939119338989257 LR: 0.13209517300128937 Accuracy: 82.14285714285714\n",
      "Epoch: 3 Training Loss: 0.4856507107615471 Validation loss: 0.4322864055633545 LR: 0.13217946887016296 Accuracy: 80.51948051948052\n",
      "Epoch: 4 Training Loss: 0.49688638374209404 Validation loss: 0.4267978370189667 LR: 0.1316411793231964 Accuracy: 81.81818181818183\n",
      "Epoch: 5 Training Loss: 0.47215772792696953 Validation loss: 0.4256918549537659 LR: 0.13171322643756866 Accuracy: 81.4935064935065\n",
      "Epoch: 6 Training Loss: 0.4647515192627907 Validation loss: 0.4272987425327301 LR: 0.13168056309223175 Accuracy: 80.51948051948052\n",
      "Epoch: 7 Training Loss: 0.4632263034582138 Validation loss: 0.42952250242233275 LR: 0.1307843178510666 Accuracy: 81.16883116883116\n",
      "Epoch: 8 Training Loss: 0.5070247277617455 Validation loss: 0.42406185865402224 LR: 0.1309865564107895 Accuracy: 81.4935064935065\n",
      "Epoch: 9 Training Loss: 0.4706702083349228 Validation loss: 0.426563161611557 LR: 0.13093183934688568 Accuracy: 81.81818181818183\n"
     ]
    }
   ],
   "source": [
    "# LALR, BCE\n",
    "trainLALR(modelLALR_BCE, train_loader, test_loader, optimizerLALR_BCE, criterion_, tau, 10, ls_list_LALR_BCE, val_list_LALR_BCE, acc_list_LALR_BCE, 2, \"BCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: -0.7770247459411621 Validation loss: -0.7739135503768921 Accuracy: 76.94805194805194\n",
      "Epoch: 1 Training Loss: -0.7783898040652275 Validation loss: -0.7774721384048462 Accuracy: 76.94805194805194\n",
      "Epoch: 2 Training Loss: -0.7829556688666344 Validation loss: -0.781208086013794 Accuracy: 75.97402597402598\n",
      "Epoch: 3 Training Loss: -0.7859740480780602 Validation loss: -0.7849595069885253 Accuracy: 75.97402597402598\n",
      "Epoch: 4 Training Loss: -0.7938391640782356 Validation loss: -0.7890154480934143 Accuracy: 75.64935064935064\n",
      "Epoch: 5 Training Loss: -0.7850734740495682 Validation loss: -0.7928719997406006 Accuracy: 75.32467532467533\n",
      "Epoch: 6 Training Loss: -0.7957627922296524 Validation loss: -0.7969919323921204 Accuracy: 75.32467532467533\n",
      "Epoch: 7 Training Loss: -0.794424831867218 Validation loss: -0.80098876953125 Accuracy: 75.32467532467533\n",
      "Epoch: 8 Training Loss: -0.7950630933046341 Validation loss: -0.8051639199256897 Accuracy: 75.32467532467533\n",
      "Epoch: 9 Training Loss: -0.804638683795929 Validation loss: -0.8094724416732788 Accuracy: 74.35064935064936\n"
     ]
    }
   ],
   "source": [
    "# CLR, sBQC\n",
    "trainConstantLR(modelCLR_sBQC, train_loader, test_loader, optimizerCLR_sBQC, criterion, tau, 10, ls_list_CLR_sBQC, val_list_CLR_sBQC, acc_list_CLR_sBQC, \"sBQC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 0.5324735753238201 Validation loss: 0.5011018574237823 Accuracy: 78.8961038961039\n",
      "Epoch: 1 Training Loss: 0.5489542819559574 Validation loss: 0.4989452838897705 Accuracy: 78.57142857142857\n",
      "Epoch: 2 Training Loss: 0.5122137703001499 Validation loss: 0.49607136845588684 Accuracy: 78.57142857142857\n",
      "Epoch: 3 Training Loss: 0.5235667899250984 Validation loss: 0.49385645389556887 Accuracy: 78.57142857142857\n",
      "Epoch: 4 Training Loss: 0.5311433337628841 Validation loss: 0.4914563655853271 Accuracy: 78.8961038961039\n",
      "Epoch: 5 Training Loss: 0.5213596038520336 Validation loss: 0.48894195556640624 Accuracy: 78.8961038961039\n",
      "Epoch: 6 Training Loss: 0.5140591450035572 Validation loss: 0.48683532476425173 Accuracy: 79.22077922077922\n",
      "Epoch: 7 Training Loss: 0.5082472302019596 Validation loss: 0.48434029817581176 Accuracy: 79.22077922077922\n",
      "Epoch: 8 Training Loss: 0.5371161811053753 Validation loss: 0.4826871454715729 Accuracy: 79.54545454545455\n",
      "Epoch: 9 Training Loss: 0.5371801927685738 Validation loss: 0.481396746635437 Accuracy: 79.54545454545455\n"
     ]
    }
   ],
   "source": [
    "# CLR, BCE\n",
    "trainConstantLR(modelCLR_BCE, train_loader, test_loader, optimizerCLR_BCE, criterion_, tau, 10, ls_list_CLR_BCE, val_list_CLR_BCE, acc_list_CLR_BCE, \"BCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1521e9e3d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwd0lEQVR4nO3deXgV1d3A8e+5uTe52fd9hUSQ1QCRrS4giopYlFoVtUJba31dKm9r69JW2z62datal7aKtuKrglVLRaUuIEJd2Pct7AkhIQnZ9/W8f8zNBlkgN8ncm/v7PM88M3fm3Du/jPg7M+fMnFFaa4QQQgx+FrMDEEIIMTAk4QshhIeQhC+EEB5CEr4QQngISfhCCOEhrGYH0J2IiAidkpJidhhCCOE2Nm/efFJrHdnZNpdO+CkpKWzatMnsMIQQwm0opbK62iZNOkII4SEk4QshhIeQhC+EEB7CqYSvlApTSn2mlDrgmId2Uma4Umpbu6lcKbXQmf0KIYQ4e86e4T8ArNJanwOscnzuQGudqbVO11qnAxOAamCZk/sVQghxlpxN+HOAxY7lxcA1PZSfARzSWnfZiyyEEKJ/OJvwo7XWeQCOeVQP5W8ElnRXQCl1u1Jqk1JqU2FhoZPhCSGEaNHjffhKqZVATCebfnk2O1JKeQPfBh7srpzW+mXgZYCMjIzejd285gmw+UFANARGG/OAKLCHgFK9+kkhhHB3PSZ8rfWlXW1TSuUrpWK11nlKqVigoJufuhLYorXO70WcZ05r+Oo5qK84fZuXT1vyD4iGgEjwj3J8juq47BPYr2EKIcRAc/ZJ2+XAfOAxx/z9bsrOo4fmnD6hFDx4DGrLoLIAKvM7ThX5UHkCSo5CzgaoOgl0ciHhHQCBsRAY0zYPimv77B9pVBo+Af3+JwkhRF9wNuE/BvxTKfVDIBv4LoBSKg54RWs9y/HZD7gM+LGT+zszSoFviDFFDuu+bFMjVBdBVYGjgmhXSZTnQsUJOLbemDfVnf59m98pVwfRHa8iWpqU/KPA6t0ff60QQpwRpxK+1roI486bU9fnArPafa4Gwp3ZV7/xshpJOTC6+3JaQ00JVOQZU2WhUSlUFbZVEEUHIesro1xnfMOMK4SAKAiIade/EO1Y71gnzUlCiH7g0oOn9VZ5bQP+3la8LH3YQasU+IUZU/So7ss21juuGFqakE5tUsqHoq+MeVP96d/3DmjXlBQLQbFtyy2fA6LB6tN3f58QYtAbdAm/pKqeOS9+xZz0OH42c7g5QVi9ITjBmLrTctVQmW80GVUWGP0LFSeMq4jyvO6bk/zC2/UztK8g4o3+hqB4o4KSO5OEEAzChB/iZ2PSkDCe//wgYxNCuGxkD001Zmp/1RA1outy7ZuTyh1NShUnoCK3rXLI321UHLq543et9rbkHxTXthyc0Db3DZVKQQgPoLTu3a3uAyEjI0P3Zjz82oYmrvvb12SdrGb5PRcwJMK/H6JzQU2NRlNSeS6UH2+bl7VbrsiD5saO37P5tasU4tuuFlqbkmKMJiQvmzl/lxDijCmlNmutMzrdNhgTPsCx4mqufuFLogPtLLtrKn7eg+5ipneam4ymo/LjUJbTrkLIMeYVJ4xmpVMrBZRxK2rrFUJ8WwXRshwYK3ciCWEyj0z4AGv3FzL/Hxu4emwcf74xHSXNFmemuRmqT7Y1HbXcnlqR67hSyDUqh7qyU76ojDuQ2l8ttK8YWtZ7SeUrRH/pLuEP6v/zLhoWyX0zh/PkJ5mkJ4bwgwuGmB2Se7BY2p44jj2v63J1FY7kn9OuGclxxVB0CI6shbryjt9RFgiMg5AkCEmE4MR28ySjT8Hm279/nxAealAnfID/uTiVrdml/GHFXkbHBzNxSJjZIQ0ePoEQOdyYulJb3q4vIQfKjkHpMWOe9Q2Uvwu6qeN3/CMdyb+lMnBUDiFJxiTPKQjRK4O6SadFeW0Dc174isq6Rj665wKigux9EJ3oE02NRtNRaXa7yiC7rVIoPXb6Lam+YUbiD012VALJxtTyWa4QhAfz2Db89jJPVHDNi18xKi6It340GW+rvN3RLTQ3G08zlx2D0iyjYijNhpJ2y6dWCAExjuSfDKEp7ZaTjeYk6UMQg5gkfIcPtudyz5KtLJiawm++3cPTssI9NDcbt6KWZBkVQkmWMTBey3J5TsdnEyxWo+O45cqg/VVCaIpx+6lFTgaE+/LYTttTXX1eHNuOlfLql0fISAll9tg4s0MSzrJY2p40Tpp0+vamBuPqoPWKIKvtCuHgSuMW1Pas9nZXBu2msCEQOgRs0hwo3JdHJXyAB648l81ZJfxy2S4mJIcSGyztvYOalw3ChhpTZxpqjM7kkqOnTFnGQHj1le0KK6MjOTzVmMJSITzNWA5JkgfThMvzqCadFkdOVjHrz/9lfHII//eDSVj6cpA1MXhoDdXFUHIEig8bt5oWHzJGRS063PE5BIvVuAKIOMeoBCKGOZbPAX/XHChWDE7SpHOKIRH+PHz1SB78107+8fVRfij354vOKGUka/9wSDjl/x+tjfcoFB00KoKiA3DygPH54MqOo6D6hhpXGKEppzcXyYNoYgB57L+0G89PZNXeAh7/eB8XpEUwPEbu7RZnQSnwjzCmpMkdtzU3GX0FJw+2VQQlR+H4FtjzfsdhKyxWo5koNMXR9OToK2ipILz9BvCPEoOdRzbptDhZWccVz64lIsCH9+/+Fj5Wr37blxCA47mD3NP7DIodzUa1pR3LB8QYyT8izdFfcI7RVBSaIn0GolNyW2Y3Pt+Xzw9e28SPLxrKg7O6GaJYiIFQU9KW/EuOGMtFjn6D6pNt5ZSXkfRb+gzC09r6DAKiZLhrDyZt+N245NxobpqUxMv/Pcy04VFMSZUONmEi31CID4X48advqykxkv/JAx37DA5/AY21beV8gjpWAhHnQOS5xl1FMpqpR/P4M3yA6vpGrnruS+oamvjPwosI9pVLZeFGmpuNZw2KDrT1GxQdNJbLc9rKKS+jjyDyXOMuopZxkCKGgbeHvDPCA0iTzhnYdqyU7/z1a64eG8uzN44bkH0K0e/qq4wrgZP7oTATTmYa8+LD7TqPlfEcQeS5EHUuRI5oqwykInA70qRzBtITQ/jJJefwzMr9XDIimm+fJ0/hikHA2x/i0o2pvcZ6o4+gcJ9RARTug4J9cHh1u1tKHRVB9GiIHmVMMWOMvgOL3ODgjiTht3PX9FS+2F/Ar5btZGpqOBEBPmaHJET/sHp3PrR1U6NRERTsNSqCgj3G+5L3/6dtTCKbn/EO5ujRxhQzBmJGy7DVbkCadE5xsKCSmc+s4bYLh/KQ3LUjhKGhxqgA8ncZFUD+LjixC2qK28qEDXUk/zEQc54xD4yRO4YGmDTpnIW0qACuSY/n9W+O8qMLhxIZKGf5QmDzPb1pSGvjXQYndsKJHcY8b4fxcFkL/0jjrWmx50FsujEPSZJKwCSS8Dtxz4xzeH97Li+tOcSvZo80OxwhXJNSjvcUx8Gwy9vW15YbVwEndhgVQN42OLS67c1mvqHtKgFHRRA6RIalHgCS8DsxJMKfa9LjeWN9FrdfPJSoQBkSV4gzZg+C5CnG1KKhFgp2Q+42yNtuVALf/AWaG4ztPkEQM9a4gmipCMLTpHO4j0nC78I9l6Tx723HeWnNYX4tZ/lCOMdmh/gJxtSisR4K93asBDYsanuDmc0fYsdC3HjjQbS4cUY/gTQH9Zok/C6kRPhz7bh43liXxY8vGirvwRWir1m9287mWzQ1GM8M5G4zKoDcrbDxFVjnqATsIUbijx/fVhEEyS3UZ0ru0ulGVlEVl/xpDfOnpPDw1XKWL4QpmhqM20NztxojjuZugfw9bX0CATHtKoBxxtwvzNyYTSR36fRScrg/c8fF8+b6LO64WM7yhTCFl63tSmDCAmNdQ41xV1BLBXB8C2SuaPtO6BCj+SjhfEicaNwiKqOLSsLvyd2XpPGvrcf5yxeH5MXnQrgKm6+RyBMntq2rLTOagloqgOxvYNe7xjarr9EU1PKdhIkQEGlK6GaSJp0z8It3t/Pvbbn89xfTiZazfCHcR9lxyNkAxxxT3va2O4NCUyA+w3ElkGHcJTQIXlIvg6c5Kbuomkv+9AW3TE6Ws3wh3FlDjZH0j62HnE1wfDOUHze2WazGUBEJLZXAROMF9W52V1C/teErpcKAt4EU4Chwvda6pJNy/wvcBmhgJ/B9rXXtqeVcVVK4H98Zn8BbG7K54+JUYoLd/yxACI9k8zVeSdn+tZTleUbiP+6oALa/bdwZBOAbBomTIGmSMY8bZ/yGm3LqDF8p9QRQrLV+TCn1ABCqtb7/lDLxwJfASK11jVLqn8AKrfVrPf2+q5zhAxwrrmb6U19w86QkfjtntNnhCCH6S3OTcWtoSzPQsfXGOwbAuAqIPQ8SJ0Pi+UancHCCufGeoj/v0pkDTHMsLwa+AO7vpJwV8FVKNQB+QK6T+x1wiWF+XDchgSUbjnHHtFRig923lhdCdMPiZYwGGjUCJsw31lUVOfoC1huVwKZXYd2LxrbAOKMZKHGiUQHEprtsX4CzCT9aa50HoLXOU0pFnVpAa31cKfUUkA3UAJ9qrT91cr+muGt6Gu9uzuGvXxzid3KWL4Tn8A+H4VcaExjPBpzYCTkbjenYBti73NhmsRm3gSZNdjQHTTZGDXUBPTbpKKVWAp1F+0tgsdY6pF3ZEq116CnfDwXeA24ASoF3gHe11m90sb/bgdsBkpKSJmRlZZ3p3zIgHvzXDt7bfJx1D80gzF/eDyqEcKjIN/oBjm0wKoHjm9veNRyS3K4CmGK8XayfBovrt7t0lFKZwDTH2X0s8IXWevgpZb4LXKG1/qHj863AZK31nT39viu14bfYn1/BzGfW8uCV5/Lji1PNDkcI4aoa640RQ7PXwbF1kL0eqgqMbfZgox8gaTIkTzU6g619MxR7f7bhLwfmA4855u93UiYbmKyU8sNo0pkBuFYWPwvDogOZmBLGWxuy+dGFQ7FY3OuWLSHEALF6G237CRnA3cb7A0qOGIk/+xtjOvCJo6xjcLkkxyijiZP65Q1izp7hhwP/BJIwEvt3tdbFSqk44BWt9SxHud9iNOk0AluB27TWdT39viue4QO8v+049y7dxuIfTOTiYZ73tJ4Qoo9UnTQSf9Y3kP218f4A3QQ+wXD/0V41+8iDV32srrGJqX/8nPHJoSy6tdPjKoQQZ6+uwmj/L8+DcTf36idk8LQ+5mP14vrzE3lpzSFyS2uIC5FbNIUQfcAnEFIv6befl3eK9dJNE5PQwNIN2WaHIoQQZ0QSfi8lhvkxbVgkSzceo6Gp2exwhBCiR5LwnXDL5GQKKur4bE++2aEIIUSPJOE7YdrwKOJDfPm/b1zr4TAhhOiMJHwneFkUN01K4pvDRRwsqDQ7HCGE6JYkfCddn5GIzUvx5no5yxdCuDZJ+E6KDPTh8lExvLc5h5r6JrPDEUKILknC7wO3TE6mvLaRD7a73ajPQggPIgm/D0waEsY5UQG8Ic06QggXJgm/DyiluHlSEjtyytiRU2p2OEII0SlJ+H1k7oQEfG1evLFOzvKFEK5JEn4fCbLbmJMex/LtuZRVN5gdjhBCnEYSfh+6ZXIytQ3NvLclx+xQhBDiNJLw+9Do+GDOSwzhrQ3ZuPKw00IIzyQJv4/dNDGRgwWVbM4qMTsUIYToQBJ+H5s9Ng5/by+WbDhmdihCCNGBJPw+5u9j5dvp8Xy0M5eyGum8FUK4Dkn4/eDG8xOpbWhm+bbjZocihBCtJOH3g7EJwYyIDWLJhmPSeSuEcBmS8PuBUop5ExPZk1fOruPlZocjhBCAJPx+Myc9HrvNwpKN8s5bIYRrkITfT4J9bcwaE8vybblU1TWaHY4QQkjC70/zJiZRWdfIRzvyzA5FCCEk4fenjORQUiP9pVlHCOESJOH3I6UUN56fxNbsUjJPVJgdjhDCw0nC72dzx8dj81IslbN8IYTJJOH3s/AAH2aOimHZ1uPUNsg7b4UQ5pGEPwDmnZ9EaXUDn+w+YXYoQggPJgl/AExNDScxzJclG6RZRwhhHkn4A8BiUdyQkci6w8UcOVlldjhCCA8lCX+AfDcjES+L4u2NMmyyEMIckvAHSHSQnenDo3h3cw4NTc1mhyOE8ECS8AfQvImJnKysY9XefLNDEUJ4IEn4A+jiYZHEBNl5c7103gohBp5TCV8pFaaU+kwpdcAxD+2i3L1KqV1Kqd1KqYXO7NOdWb0szJuYxH8PnJTOWyHEgHP2DP8BYJXW+hxgleNzB0qp0cCPgInAecBspdQ5Tu7Xbd040ei8fWt9ltmhCCE8jLMJfw6w2LG8GLimkzIjgHVa62qtdSOwBrjWyf26reggO5ePiuafm3LkyVshxIByNuFHa63zABzzqE7K7AIuUkqFK6X8gFlAYlc/qJS6XSm1SSm1qbCw0MnwXNMtk5Ipq2ngQxk2WQgxgHpM+EqplY7291OnOWeyA631XuBx4DPgY2A70OUbQbTWL2utM7TWGZGRkWf4Z7iXKanhDI3054110qwjhBg4PSZ8rfWlWuvRnUzvA/lKqVgAx7ygi994VWs9Xmt9EVAMHOjLP8LdKKW4ZVIy246Vsut4mdnhCCE8hLNNOsuB+Y7l+cD7nRVSSkU55knAXGCJk/t1e9+ZkIDdZpGzfCHEgHE24T8GXKaUOgBc5viMUipOKbWiXbn3lFJ7gA+Au7TWJU7u1+0F+9qYc148/952nLKaBrPDEUJ4AKcSvta6SGs9Q2t9jmNe7Fifq7We1a7chVrrkVrr87TWq5wNerD43pRkahua+deWHLNDEUJ4AHnS1kSj44M5LzGEN9ZlobU2OxwhxCAnCd9k35uczKHCKr45XGR2KEKIQU4Svslmj40l2NcmnbdCiH4nCd9kdpsX12ck8OnufPLLa80ORwgxiEnCdwE3TUqmsVmzdIO8HEUI0X8k4buAIRH+XHhOBEs2ZNMoL0cRQvQTSfgu4pbJyZwor2XVvk4fVhZCCKdJwncRM86NIjbYLp23Qoh+IwnfRVi9LNwkL0cRQvQjSfgu5IaJiXh7WXj1y8NmhyKEGIQk4buQqEA735mQwD835VAgt2gKIfqYJHwXc8fFQ2lsaubVL4+YHYoQYpCRhO9iksP9mT02jjfWZVFWLaNoCiH6jiR8F/Q/01Kpqm9i8TdHzQ5FCDGISMJ3QSNig5hxbhT/+OoI1fVdvg1SCCHOiiR8F3Xn9DRKqhtYIsMtCCH6iCR8FzUhOZTJQ8NYtPYwdY1NZocjhBgEJOG7sLump3GivJZlW46bHYoQYhCQhO/CLkiLYEx8MH9bc4imZnkjlhDCOZLwXZhSirump3K0qJoVO/PMDkcI4eYk4bu4mSNjSI3058XVB+W9t0IIp0jCd3EWi+J/pqWx70QFqzNl6GQhRO9JwncDc9LjiA/x5cXVh+QsXwjRa5Lw3YDNy8KPLx7K5qwSNhwpNjscIYSbkoTvJq7PSCQiwJsXvzhkdihCCDclCd9N2G1e/OCCIazdX8jW7BKzwxFCuCFJ+G7k1ikpRAR489h/9klbvhDirEnCdyMBPlZ+MuMc1h8p5ovMQrPDEUK4GUn4bmbexCRSwv147D/75OlbIcRZkYTvZmxeFu67fDiZ+RUs2ypj7AghzpwkfDd01ZhYzksI5ulPM6ltkJE0hRBnRhK+G1JKcf+V55JbVsvr8lYsIcQZkoTvpqamRjBteCQvrj4k774VQpwRSfhu7P4rzqW8toG/rDlodihCCDfgVMJXSn1XKbVbKdWslMroptwVSqlMpdRBpdQDzuxTtBkRG8S14+L5x1dHyS2tMTscIYSLc/YMfxcwF1jbVQGllBfwInAlMBKYp5Qa6eR+hcNPLxsGGp75bL/ZoQghXJxTCV9rvVdrndlDsYnAQa31Ya11PbAUmOPMfkWbhFA/5k9N5r0tOWSeqDA7HCGECxuINvx44Fi7zzmOdZ1SSt2ulNqklNpUWChPk56JO6el4e9j5YmP95kdihDChfWY8JVSK5VSuzqZzvQsXXWyrstHRLXWL2utM7TWGZGRkWe4C88W6u/NndPSWLWvgPWHi8wORwjhonpM+FrrS7XWozuZ3j/DfeQAie0+JwC5vQlWdO3730ohJsjOH1bslSEXhBCdGogmnY3AOUqpIUopb+BGYPkA7Nej2G1ePDjrXLbnlPH85wfMDkcI4YKcvS3zWqVUDjAF+Egp9YljfZxSagWA1roRuBv4BNgL/FNrvdu5sEVn5qTHM3d8PH9edYCvD500OxwhhItRrjyuekZGht60aZPZYbiVqrpGrn7hSyprG1lx74VEBPiYHZIQYgAppTZrrTt9LkqetB1k/H2svHjTeEprGvjpP7fTLO35QggHSfiD0IjYIB6ePZK1+wt5ae1hs8MRQrgISfiD1M2TkrhqTCxPfZrJ5qxis8MRQrgASfiDlFKKP35nDHEhdu55ayul1fVmhySEMJkk/EEsyG7jhXnjKays4753dsiLz4XwcJLwB7nzEkN44MoRrNybzz++Omp2OEIIE0nC9wA/+FYKl46I5o//2cuOnFKzwxFCmEQSvgdQSvHUd8cSGeDD/7yxhYKKWrNDEkKYQBK+hwjx8+al72VQXFXPD1/bRHV9o9khCSEGmCR8DzImIZjn541jd24ZP1myVQZZE8LDSML3MJeOjOY33x7Fyr0F/O6D3XLnjhAexGp2AGLg3Tolheyial758giJYX7cduFQs0MSQgwASfge6qFZIzheWsPvV+wlIdSXK0bHmh2SEKKfSZOOh7JYFM/ckE56Ygj3Lt3G1uwSs0MSQvQzSfgezG7zYtGtGUQH2blt8Sayi6rNDkkI0Y8k4Xu4iAAfXvv++TRpzYLXNsiYO0IMYpLwBUMjA3j5exnkFNcwb9F6TpTJg1lCDEaS8AUAE4eEsWh+BtlFVVzz4lfszSs3OyQhRB+ThC9aXTwsknfumArAd//2DWv3F5ockRCiL0nCFx2MjAti2V1TSQj15fuvbeTtjdlmhySE6COS8MVpYoN9eeeOKXwrLYL739vJU59kyhO5QgwCkvBFpwLtNl6dn8GN5yfywuqDLHx7G3WNTWaHJYRwgjxpK7pk87Lwx7ljSAr344mPM8krq+Vvt0wgzN/b7NCEEL0gZ/iiW0op7pyWxp9vTGdbdilXPLuW/x6Qzlwh3JEkfHFG5qTH8++7vkWwr43vvbqB332wh9oGaeIRwp1IwhdnbGRcEB/ccwHzpyTz96+OcM2LX7HvhNyvL4S7kIQvzord5sVv54zmH98/n5OV9Xz7ha/4+5dHaJaXqQjh8iThi16ZPjyKjxdeyEXnRPC7D/cw/x8bKCiXIRmEcGWS8EWvRQT4sOjWDB69ZjQbjxZz+bNreWfTMTnbF8JFScIXTlFKccvkZD6850KGRPjz83d3cMPL30jbvhAuSBK+6BNpUQG8e8dUHv/OGA4WVHLVc1/y6Id7qKxrNDs0IYSDJHzRZywWxQ3nJ/H5z6ZxfUYCr3x5hBl/+oIPd+TK0AxCuABJ+KLPhfp788e5Y/nXnVOJCPDh7re2cuvfN3C4sNLs0ITwaJLwRb8ZnxTK8rsv4LffHsW27FJmPrOWX7y7XV6lKIRJlDOX2kqp7wK/AUYAE7XWm7oo93dgNlCgtR59pr+fkZGhN23q+JMNDQ3k5ORQWyu3APY3u91OQkICNpvN6d8qqKjlL6sP8daGbJqaNXPHxXP3JWkkh/v3QaRCiBZKqc1a64xOtzmZ8EcAzcBLwH3dJPyLgErgdWcT/pEjRwgMDCQ8PBylVK9jF93TWlNUVERFRQVDhgzps9/NL6/lb2sO8db6bBqbNdekG4l/SIQkfiH6QncJ36kmHa31Xq115hmUWwsUO7OvFrW1tZLsB4BSivDw8D6/kooOsvPI1aP47y+ms2BqCh/tzGXGn77gp29v42BBRZ/uSwjRkcsNj6yUuh24HSApKamrMgMZksfqz+McFWTn17NHcsfFqby89hBvrMvmX1uP8620cL43OZlLR0Rj9ZIuJiH6Uo8JXym1EojpZNMvtdbv93VAWuuXgZfBaNLp698XriUy0IdfXmUk/qUbj/HW+mzueGMLMUF25k1M4saJiUQH2c0OU4hBoceEr7W+dCACEZ4tPMCHu6anccfFqazeV8D/rcvimZX7ef7zA8wcFc0tk5OZMlSa8oRwhlwz90JAQECX2+69917i4+Npbm5uXffaa69x9913n1Y2JSWFMWPGMHbsWC6++GKysrLOOpZp06YxfPhw0tPTGTFiBC+//HLrtrKyMm699VZSU1NJTU3l5ptvpqSkpHX7/v37mTVrFmlpaYwYMYLrr7+e/Pz8s46hL3lZFJeOjGbxDyay5ufT+MEFQ/j6UBE3LVrPhU+s5vcf7WFzVomM1yNELzjVhq+UuhZ4HogEPlJKbdNaX66UigNe0VrPcpRbAkwDIpRSOcAjWutXnQsdfvvBbvbk9u2YLSPjgnjk6lG9+m5zczPLli0jMTGRtWvXMm3atB6/s3r1aiIiInjkkUd49NFHWbRo0Vnv98033yQjI4Pi4mJSU1NZsGAB3t7e/PCHP2T06NG8/vrrADzyyCMsWLCA999/n9raWq666iqefvpprr766tZYCgsLiY6OPusY+kNyuD8PzRrBTy8bxoqdeXy4I4/Xvj7Kov8eISbIzhWjY7hydAwZKWF4WeTMX4ieOJXwtdbLgGWdrM8FZrX7PM+Z/biL1atXM3r0aG644QaWLFlyRgm/xZQpU3juuee63F5VVcX1119PTk4OTU1N/PrXv+aGG27oUKayshJ/f3+8vLw4ePAgmzdv5u23327d/vDDD5OamkpmZiZfffUVU6ZMaU32ANOnTz/zP3YA2W1ezB2fwNzxCZTXNvD53gJW7MxjyYZsXvv6KBEBPlw+KprLR8UweWg43la5cBWiMy53l87Z6O2ZeH9ZsmQJ8+bNY86cOTz00EM0NDSc8UNLH3/8Mddcc0232+Pi4vjoo48Ao7mmxc0334yPjw8HDhzg2WefxcvLiz179pCeno6Xl1drOS8vL8aNG8fevXvZtWsXEyZM6N0faqIgu41rxsVzzbh4quoaWZ1ZwH92nuBfW47z5vpsAn2sXDw8kstGRjP93CiC7M4/NCbEYOHWCd+V1NfXs2LFCp555hkCAwOZNGkSn376KVdddVW335s+fTr5+flERUXx6KOPdlluzJgx3Hfffdx///3Mnj2bCy+8sHVbS5NOYWEhU6dO5YorrkBr3WkH52AaxMzfx8rssXHMHhtHbUMTXx44yWd78lm1L58Pd+RhtSimpIZz2choLh0RTVyIr9khC2EqSfh95OOPP6asrIwxY8YAUF1djZ+fX48Jf/Xq1fj7+7NgwQIefvhhnn766U7LDRs2jM2bN7NixQoefPBBZs6cycMPP9yhTGRkJOPHj2f9+vWMHz+erVu30tzcjMViNHE0NzezY8cOxo8fT1FREWvWrOmDv9w12G1eXDoymktHRtPUrNl2rIRP9+Tz2e58Hn5/Nw+/v5uhEf5MGhrO5KFhTBkaTpTc7ik8jDR29pElS5bwyiuvcPToUY4ePcqRI0f49NNPqa7ueaAwX19fnn32WV5//XWKizt/IDk3Nxc/Pz9uueUW7rvvPrZs2XJamerqarZu3UpqaippaWmMGzeuw1XDo48+yowZM0hKSuKmm27i66+/bm0iAqPS2rlzZy/+etfiZVFMSA7jwStH8Pl901j504v55awRDInw58Ptudy7dBsT/7CKS/70BQ8t28ny7bmcKKsdVFc/QnRGzvB7obq6moSEhNbPd955J5988gkvvfRS6zp/f38uuOACPvjgA8C4NfPf//536/Z169Z1+M3Y2FjmzZvHiy++yK9//evT9rlz505+/vOfY7FYsNls/PWvf23ddvPNN+Pr60tdXR0LFixobZv/+9//zj333ENaWhplZWWcf/75rfH4+vry4YcfsnDhQhYuXIjNZmPs2LH8+c9/dv4AuZi0qADSogL40UVDaWxqZk9eOesOF7HucDHLt+Xy1vpsAML8vRkRG8iImCDOjQ1iRGwgaVEB+Fi9etiDEO7BqcHT+ltng6ft3buXESNGmBSR+8rMzGTWrFk8//zzzJo1q+cvOAz2491SAWzOKmFvXjn7TlSQeaKCukbjOQqrRZEaGcCo+CAmJIeSkRzGOVEBWOQ2UOGiuhs8Tc7wPcTw4cM5dOiQ2WG4HKuXhbEJIYxNCGld19jUzNGiavbmlbdOazIL+deW4wAE2q2MTwolIzmUCSmhpCeG4Oct/ysJ1yf/Sl1MUVERM2bMOG39qlWrCA8PNyEiz2P1srQ2A119Xhxg3N2UVVTNpqwSNmeVsDmrmD99VggYfQZpkQEMjwlkeEwgw6IDGR4dSEKor1wJCJciCd/FhIeHs23bNrPDEKdQSpES4U9KhD/XTTD6b8qqG9hyrIQtWSXsyS1nS3YJy7fntn7H1+bFsOgAowJwVAbDowOJDPSRMYGEKSThC9FLwX42pg+PYvrwqNZ1lXWNHMivYH9+BZknKtmfX8HqzELe2ZzTWibUz9aa/IfHBDE8JoAhEQGE+tmkIhD9ShK+EH0owMfKuKRQxiWFdlhfVFlHZr7RIZx5ooJ9Jyp4Z3MO1fVNrWUC7VZSwv1JDvdrm0cY88gAuSoQzpOEL8QACA/wYWqAD1NTI1rXNTdrjpfWsD+/gqNF1WQVVXHkZBU7cspYsTOP9gOC+lgtxIf6Eh/iS0KoHwmhvo7Jj/gQXyIDfWQAOdEjSfhCmMRiUSSG+ZEY5nfatvrGZo6X1nC0qIrsomqOl9aQU1JNTkkNu3NPUFxV36G81aKIDrITG2wnJthOXIgvscEtn32JDvIhIsAHm7xFzKNJwu+FEydOsHDhQjZu3IiPjw8pKSk8++yzzJ07l127dnUou2DBAtasWUNwcDBaa55++ulO78Lpzm9+8xsWLVpEZGQktbW1TJ8+nRdffBGLxYLWmt///vcsXrwYpRSxsbE8//zzjB07FjBG0PzZz37GypUrsdvthIeH8+STTzJp0qQ+Ox6i73lbLQyJ8O/y5e5VdY2tlcDx0lrySms4UVZLblkNO4+X8emefOobmzt8RykI9/chOsiHqEAfooPsRDkqibgQX+KC7cSG+BLgI2lhsHLv/7L/eQBO9PFQADFj4MrHutystebaa69l/vz5LF26FIBt27Z1++KQJ598kuuuu47Vq1dz++23c+DAgbMO63//93+57777aG5u5qKLLmLNmjWtif/rr79m+/bt+Pn58emnn3L11VezZ88e/P39ue222xgyZAgHDhzAYrFw+PBh9u7de9b7F67F38fKsGjjFtDOaK0prqonr6yW/PJa8svryC+vpaCijoLyWvIratmVW87JyjpOffYyyG41KoAQX2KC7YT5eRPiZyPY15hCHJ9DfG0E+9nkSWQ34t4J3wSrV6/GZrNxxx13tK5LT0/n6NGjPX53ypQpHD9+vNsyDzzwAMuXL8dqtTJz5kyeeuqpDtvr6+upra0lNNToFHz88cf54osv8PMzmgVmzpzJRRddxJtvvsmMGTNYv349b775ZusAakOHDmXo0KFn8ycLN6SUIjzAh/AAH0bHB3dZrrGpmfyKOvJKazheWkNeWa1juZa8shq2HyulpLqe7l4wFuBjJczfu8MU7piH+nsTZLcR5Gs15o7lQLtN+hxM4N4Jv5sz8f7izDjyPY15X1xczLJly9i3bx9KKUpLS1u3PfPMM7zxxhtkZWVx5ZVXkp6eTnl5OVVVVaSmpnb4nYyMDPbs2UNMTMxpY+IL0Z7Vy0J8iNEZ3Omz+Bidy5X1jZRVN1BW00BpdQOlNfXGvLqeoqp6ih3TibJa9uaVU1RVf1qT0qkCfKyOKwYboX7eBPvZCG1Z9jXmgXYrAT5WAuxW/H0cyz5W/Ly95K6lXnDvhO8mfv7zn/OLX/yCgoKC0wZNay8oKAi73c5tt93GVVddxezZs1u3tTTpNDQ0cN1117F06dIux8Rx5fGRhPuxWFTr2XniGX5Ha01VfRMlVfVU1DZSXttAeU0D5bWNjrlReZTVNFBW3UBJdT25pTWU1hiVSE+vLFYKArwdlYCjUmitHHzaKgdvqwWblwVvq2PyUo65F3abpUMl4u/4DR+rZdBWJpLwz9KoUaN49913z+o7Tz75JHPnzuW5555j/vz5bN68udNyVquVDRs2sGrVKpYuXcoLL7zA559/3qGMzWbjiiuuYO3atdx44434+/tz+PDhDs00W7ZsYebMmYwaNYrt27d3GBNfiIGglGpNpGeruVlTUdtISXU9lXWNxlTbSFV9IxW1jVTVGVN5y7JjfWVdIyfKajuU78277r0sRuxBvlZC/bwdk9F3Eebfthzq6MsIdazztbn+VYck/LN0ySWX8NBDD7Fo0SJ+9KMfAbBx48Yex723WCzce++9LF68mE8++YTLL7/8tDKVlZVUV1cza9YsJk+eTFpa2mlltNZ8/fXXpKenA8bVw09+8hPeeecdfH19WblyJbt37+bll1/GbreTkZHBI488wu9+9zuUUhw4cIA9e/YwZ84c5w+GEP3AYlEE+xkdws5qbGqmoUlT39hMXVNT63J9YzO1DU1U1TVS4ahAWiqXKkeFUVbTQImj2erwyUpKqxqoqGvscl/eVktrk1RIu3mwb8vntuVgXxv+3lZ8vb3w8/bC1+Y1IOMuScI/S0opli1bxsKFC3nsscew2+2tt2VmZmZ2GCf/mWeeOe27v/rVr3jiiSc6TfgVFRXMmTOH2lrjZRztv9/Sht/Q0MDYsWO58847AbjnnnsoLS1l7NixNDQ0UF9fz65du7Dbjbc5vfLKK/zsZz8jLS0NPz+/1tsyhfAEVi8LVi/w9fYCnK9A6hubW/svSqrqWyuEtnnb8sGCytYmqoamni81fG1e+Pt44evtRWyQL/+8Y4rT8Z5KxsMfRCorK7n22ms5//zz+cMf/tAnvynHWwjnaK2paWhqrQhaOr+r65uorm+kur6JqvomauobHfMmfKwWHvvO2F7tT8bD9xABAQF89tlnZochhGhHKYWftxU/byvxIb6mxiIJ3yTXXnstR44c6bDu8ccf77SpRwgh+oJbJnyttcv3hvdk2bJlZofQI1du7hNCnD23u1fPbrdTVFQkyaifaa0pKipq7fwVQrg/tzvDT0hIICcnh8LCQrNDGfTsdnuHu46EEO7N7RK+zWZjyJAhZochhBBux+2adIQQQvSOJHwhhPAQkvCFEMJDuPSTtkqpQiCrl1+PAE72YTh9SWLrHYmtdyS23nHX2JK11pGdbXDphO8MpdSmrh4vNpvE1jsSW+9IbL0zGGOTJh0hhPAQkvCFEMJDDOaE/7LZAXRDYusdia13JLbeGXSxDdo2fCGEEB0N5jN8IYQQ7UjCF0IIDzHoEr5S6gqlVKZS6qBS6gGz42lPKXVUKbVTKbVNKbWp52/0ezx/V0oVKKV2tVsXppT6TCl1wDEPdaHYfqOUOu44ftuUUrNMiCtRKbVaKbVXKbVbKXWvY73px62b2FzhuNmVUhuUUtsdsf3Wsd4VjltXsZl+3NrF6KWU2qqU+tDxuVfHbVC14SulvID9wGVADrARmKe13mNqYA5KqaNAhtbaJR7mUEpdBFQCr2utRzvWPQEUa60fc1SYoVrr+10ktt8AlVrrpwY6nnZxxQKxWustSqlAYDNwDbAAk49bN7Fdj/nHTQH+WutKpZQN+BK4F5iL+cetq9iuwOTj1kIp9VMgAwjSWs/u7f+ng+0MfyJwUGt9WGtdDywF5pgck8vSWq8Fik9ZPQdY7FhejJEwBlwXsZlOa52ntd7iWK4A9gLxuMBx6yY202lDpeOjzTFpXOO4dRWbS1BKJQBXAa+0W92r4zbYEn48cKzd5xxc5B+8gwY+VUptVkrdbnYwXYjWWueBkUCAKJPjOdXdSqkdjiYfU5qbWiilUoBxwHpc7LidEhu4wHFzNEtsAwqAz7TWLnPcuogNXOC4Ac8CvwCa263r1XEbbAm/s/ceukxNDXxLaz0euBK4y9FsIc7cX4FUIB3IA/5kViBKqQDgPWCh1rrcrDg600lsLnHctNZNWut0IAGYqJQabUYcnekiNtOPm1JqNlCgtd7cF7832BJ+DpDY7nMCkGtSLKfRWuc65gXAMowmKFeT72gLbmkTLjA5nlZa63zH/5jNwCJMOn6Odt73gDe11v9yrHaJ49ZZbK5y3FporUuBLzDayF3iuLVoH5uLHLdvAd929P8tBS5RSr1BL4/bYEv4G4FzlFJDlFLewI3AcpNjAkAp5e/oSEMp5Q/MBHZ1/y1TLAfmO5bnA++bGEsHLf/AHa7FhOPn6OB7FdirtX663SbTj1tXsbnIcYtUSoU4ln2BS4F9uMZx6zQ2VzhuWusHtdYJWusUjHz2udb6Fnp73LTWg2oCZmHcqXMI+KXZ8bSLayiw3THtdoXYgCUYl6oNGFdHPwTCgVXAAcc8zIVi+z9gJ7DD8Q8+1oS4LsBoJtwBbHNMs1zhuHUTmysct7HAVkcMu4CHHetd4bh1FZvpx+2UOKcBHzpz3AbVbZlCCCG6NtiadIQQQnRBEr4QQngISfhCCOEhJOELIYSHkIQvhBAeQhK+EEJ4CEn4QgjhIf4f9WPbtWWhTMAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# error plots\n",
    "# plt.plot(range(10), ls_list_LALR_sBQC)\n",
    "plt.plot(range(len(val_list_LALR_sBQC)), val_list_LALR_sBQC, label= \"LALR_sBQC\")\n",
    "# plt.plot(range(len(ls_list_LALR_sBQC)), ls_list_LALR_sBQC, label= \"LALR_sBQC_ls\")\n",
    "plt.plot(range(len(val_list_CLR_sBQC)), val_list_CLR_sBQC, label= \"CLR_sBQC\")\n",
    "# plt.plot(range(len(val_list_LALR_sBQC)), val_list_LALR_BCE, label= \"LALR_BCE\")\n",
    "# plt.plot(range(len(val_list_CLR_sBQC)), val_list_CLR_BCE, label= \"CLR_BCE\")\n",
    "# plt.plot(range(len(acc_list_CLR_BCE)), acc_list_CLR_BCE, label= \"CLR_BCE_acc\")\n",
    "# plt.plot(range(len(acc_list_CLR_sBQC)), acc_list_CLR_sBQC, label= \"CLR_sBQC_acc\")\n",
    "# plt.plot(range(len(acc_list_LALR_BCE)), acc_list_LALR_BCE, label= \"LALR_BCE_acc\")\n",
    "# plt.plot(range(len(acc_list_LALR_sBQC)), acc_list_LALR_sBQC, label= \"LALR_sBQC_acc\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics:\n",
    "def computeMetrics(model):\n",
    "    outputs= torch.Tensor([])\n",
    "    outputs= outputs.to(device)\n",
    "    labels= torch.Tensor([])\n",
    "    labels= labels.to(device)\n",
    "    for inputs, label in test_loader:\n",
    "        inputs= inputs.to(device)\n",
    "        label= label.to(device)\n",
    "        output= model(inputs)\n",
    "        outputs= torch.cat((outputs, output))\n",
    "        labels= torch.cat((labels, label))\n",
    "    x= outputs\n",
    "    x= torch.where(outputs.view(outputs.shape[0]) > 0.5, 1, 0)\n",
    "    CP= cohen_kappa_score(labels.detach().to('cpu').numpy(), x.detach().to('cpu').numpy())\n",
    "    JS= jaccard_score(labels.detach().to('cpu').numpy(), x.detach().to('cpu').numpy())\n",
    "    F1= f1_score(labels.detach().to('cpu').numpy(), x.detach().to('cpu').numpy())\n",
    "    return [CP, JS, F1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3790322580645161, 0.3474576271186441, 0.5157232704402516]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeMetrics(modelLALR_sBQC)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
