{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## LALR testing for sBQC loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#My imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from adahessian import Adahessian, get_params_grad\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import math\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Other imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import auc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "# import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loss function code:\n",
    "\n",
    "def bareCDF(yhat, tau):\n",
    "    # yhat is a torch tensor, tau is a float\n",
    "    ind= (torch.sign(yhat)+1)/2 # mask about the origin\n",
    "    quantFactor= (1-tau)*ind + tau*(1-ind)\n",
    "    val= tau+4*quantFactor/math.pi*torch.atan(torch.tanh(yhat/2))\n",
    "    # print(\"bareCDF val: {}\".format(val))\n",
    "    return val\n",
    "\n",
    "def baresBQR(y, yhat, tau):\n",
    "    # y and yhat are torch tensors, tau is a float\n",
    "    val= torch.matmul(y,torch.log(1-bareCDF(yhat, tau)))+ torch.matmul((1-y),torch.log(bareCDF(yhat, tau)))\n",
    "    # print(\"bareBQR val: {}\".format(val))\n",
    "    return val\n",
    "\n",
    "class sBQRL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sBQRL, self).__init__()\n",
    "    \n",
    "    def forward(self, y, yhat, tau):\n",
    "        return baresBQR(y, yhat, tau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2744/1411682212.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_X_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_X_unscaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mditch_head\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mremove_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mshap_x_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mshap_x_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2744/1411682212.py\u001b[0m in \u001b[0;36mcreate_xy\u001b[0;34m(dataset, attribute_columns, target_column, delim, split_ratio, ditch_head)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mX_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mX_unscaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dataset= \"./Datasets/Classification/ILP.csv\"\n",
    "x_cols = list(range(10))\n",
    "y_col = 10\n",
    "separator = \",\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# attribute_index =   # This controls which attribute is allowed to vary, 7,5\n",
    "attribute_name = \"BMI\" # Name of the attribute, used in the plots, max heart rate\n",
    "latent_name = \"Diabetes\" # Name of the function, used in the plots\n",
    "# The other attributes are replaced by the median value of the attribute\n",
    "Scaler= StandardScaler()\n",
    "batch_is= 64\n",
    "\n",
    "total_epochs = 20\n",
    "\n",
    "### \n",
    "def create_xy(dataset, attribute_columns, target_column, delim, split_ratio, ditch_head=True):\n",
    "    with open(dataset, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    if ditch_head:\n",
    "        lines = lines[1:]\n",
    "    X = []\n",
    "    Y = []\n",
    "    for line in lines:\n",
    "        while len(line) > 0 and line[-1] == \"\\n\":\n",
    "            line = line[:len(line)-1]\n",
    "        split_array = line.split(delim)\n",
    "        all_columns = []\n",
    "        for value in split_array:\n",
    "            if value !=\"\" and value !=\" \":\n",
    "                all_columns.append(value)\n",
    "        if len(all_columns)==0:\n",
    "            break\n",
    "        point = []\n",
    "        for i in attribute_columns:\n",
    "            point.append(float(all_columns[i]))\n",
    "        X.append(point)\n",
    "        Y.append(float(all_columns[target_column]))\n",
    "    X_arr = np.asarray(X)\n",
    "    X_unscaled = np.asarray(X)\n",
    "    Scaler.fit(X_arr)\n",
    "    X_arr = Scaler.transform(X_arr)\n",
    "    Y_arr = np.asarray(Y)\n",
    "    thresh = 0\n",
    "    Y_arr_binary = np.where(Y_arr<=thresh,0,1)\n",
    "    unique, counts = np.unique(Y_arr_binary, return_counts=True)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_arr, Y_arr_binary, test_size = split_ratio)\n",
    "    return x_train, x_test, y_train, y_test, Y_arr, X_arr, X_unscaled\n",
    "\n",
    "###\n",
    "X_train,X_val,y_train,y_val, data_Y, data_X_scaled, data_X_unscaled = create_xy(dataset, x_cols, y_col, separator, 0.4, ditch_head= remove_head)\n",
    "shap_x_train = X_train.copy()\n",
    "shap_x_val = X_val.copy()\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "# y_train= F.one_hot(y_train.to(torch.int64), num_classes=2)\n",
    "X_val = torch.Tensor(X_val)\n",
    "y_val = torch.Tensor(y_val)\n",
    "# y_val= F.one_hot(y_val.to(torch.int64), num_classes=2)\n",
    "train_dataset = data_utils.TensorDataset(X_train, y_train)\n",
    "test_dataset = data_utils.TensorDataset(X_val, y_val)\n",
    "train_loader = data_utils.DataLoader(train_dataset, batch_size =batch_is, pin_memory=True,shuffle=True,num_workers = 1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,batch_size =batch_is,pin_memory=True,shuffle = False,num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network definition:\n",
    "class LALRnetwork(nn.Module):\n",
    "    def __init__(self, indim):\n",
    "        super(LALRnetwork,self).__init__()\n",
    "        self.l1 = nn.Linear(indim,100)\n",
    "        self.l2 = nn.Linear(100,10)\n",
    "        self.l3 = nn.Linear(10,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.l1(x))\n",
    "        x = F.tanh(self.l2(x))\n",
    "        # x = F.softmax(self.l3(x))\n",
    "        x = F.sigmoid(self.l3(x))\n",
    "        # x= torch.sign(x-torch.ones_like(x)*0.5)\n",
    "        # x= (x+torch.ones_like(x))/2\n",
    "        return x\n",
    "    \n",
    "    # Used in LALR\n",
    "    def penU(self, x):\n",
    "        op = F.tanh(self.l1(x))\n",
    "        op = F.tanh(self.l2(op))\n",
    "        return op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Global initialisations:\n",
    "device= ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "indim = X_train.shape[1]\n",
    "modelLALR_sBQC = LALRnetwork(indim).to(device)\n",
    "modelCLR_sBQC= LALRnetwork(indim).to(device)\n",
    "modelLALR_BCE= LALRnetwork(indim).to(device)\n",
    "modelCLR_BCE= LALRnetwork(indim).to(device)\n",
    "modelLBFGS_sBQC = LALRnetwork(indim).to(device)\n",
    "\n",
    "criterion= sBQRL()\n",
    "criterion_= nn.BCELoss()\n",
    "h= 0.4\n",
    "lr_is = 1e-2\n",
    "optimizerLALR_sBQC= torch.optim.Adam(modelLALR_sBQC.parameters(), lr = lr_is)\n",
    "optimizerLALR_BCE= torch.optim.Adam(modelLALR_BCE.parameters(), lr = lr_is)\n",
    "optimizerCLR_sBQC= torch.optim.Adam(modelCLR_sBQC.parameters(), lr = lr_is)\n",
    "optimizerCLR_BCE= torch.optim.Adam(modelCLR_BCE.parameters(), lr = lr_is)\n",
    "optimizerLBFGS_sBQC= torch.optim.LBFGS(modelLBFGS_sBQC.parameters(), lr = lr_is)\n",
    "\n",
    "all_qs = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "all_qs = torch.Tensor(all_qs).to(device)\n",
    "mean_is = 0\n",
    "std_is = 1\n",
    "penalty = 1\n",
    "alpha = 0.0\n",
    "tau= 0.2\n",
    "\n",
    "ls_list_LALR_sBQC= []\n",
    "val_list_LALR_sBQC= []\n",
    "acc_list_LALR_sBQC= []\n",
    "ls_list_CLR_sBQC= []\n",
    "val_list_CLR_sBQC= []\n",
    "acc_list_CLR_sBQC= []\n",
    "ls_list_LALR_BCE= []\n",
    "val_list_LALR_BCE= []\n",
    "acc_list_LALR_BCE= []\n",
    "ls_list_CLR_BCE= []\n",
    "val_list_CLR_BCE= []\n",
    "acc_list_CLR_BCE= []\n",
    "\n",
    "ls_list_LBFGS_sBQC= []\n",
    "val_list_LBFGS_sBQC= []\n",
    "acc_list_LBFGS_sBQC= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training loops:\n",
    "def trainConstantLR(model, trainLoader, valLoader, optimizer, criterion, tau, epochs, ls_list, valList, acc_list, loss_name= \"sBQC\"):\n",
    "    \"\"\"\n",
    "    Training loop used for CLR training\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss= 0.0\n",
    "        # training loop\n",
    "        model.train()\n",
    "        for inputs, labels in trainLoader: \n",
    "            inputs= inputs.to(device) \n",
    "            labels= labels.to(device)\n",
    "            optimizer.zero_grad() \n",
    "            outputs= model(inputs) \n",
    "            # loss= criterion(torch.unsqueeze(labels, 1), outputs, tau) \n",
    "            # print(outputs, labels)\n",
    "            # outputs= outputs.to(torch.LongTensor()).to(device)\n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            # loss= criterion(outputs, labels) # works for one hot encoding and BCE\n",
    "            # loss= criterion(outputs, torch.unsqueeze(labels, 1))#, tau) \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            epoch_loss+= loss.item()\n",
    "        ls_list.append(epoch_loss/len(trainLoader))\n",
    "\n",
    "        # validation loop\n",
    "        val_loss= 0.0\n",
    "        num_correct= 0\n",
    "        total= 0 \n",
    "        model.eval()\n",
    "        for inputs, labels in valLoader:\n",
    "            inputs= inputs.to(device)\n",
    "            labels= labels.to(device)\n",
    "            outputs= model(inputs)\n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            val_loss+= loss.item()\n",
    "            x= torch.where(outputs.view(outputs.shape[0]) > 0.5, 1, 0)\n",
    "            num_correct += (x==labels).sum()\n",
    "            total += labels.size(0)\n",
    "        valList.append(val_loss/len(valLoader))\n",
    "        acc_list.append(float(num_correct)/float(total)*100)\n",
    "        print(\"Epoch: {} Training Loss: {} Validation loss: {} Accuracy: {}\".format(epoch, epoch_loss/len(trainLoader), val_loss/len(valLoader),\n",
    "         float(num_correct)/float(total)*100))\n",
    "\n",
    "\n",
    "def trainLALR(model, trainLoader, valLoader, optimizer, criterion, tau, epochs, ls_list, valList, acc_list, mask, loss_name= \"sBQC\"):\n",
    "    \"\"\"\n",
    "    Training loop used for LALR training\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss= 0.0\n",
    "        lr_val= computeLR(model,train_loader, mask, tau, bSize= batch_is)\n",
    "        optimizer.param_groups[0]['lr']= lr_val\n",
    "        # training loop\n",
    "        model.train()\n",
    "        for inputs, labels in trainLoader: \n",
    "            inputs= inputs.to(device) \n",
    "            labels= labels.to(device)\n",
    "            optimizer.zero_grad() \n",
    "            outputs= model(inputs) \n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            epoch_loss+= loss.item()\n",
    "        ls_list.append(epoch_loss/len(trainLoader))\n",
    "\n",
    "        # validation loop\n",
    "        val_loss= 0.0\n",
    "        num_correct= 0\n",
    "        total= 0 \n",
    "        model.eval()\n",
    "        for inputs, labels in valLoader:\n",
    "            inputs= inputs.to(device)\n",
    "            labels= labels.to(device)\n",
    "            outputs= model(inputs)\n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion_(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            val_loss+= loss.item()\n",
    "            x= torch.where(outputs.view(outputs.shape[0]) > 0.5, 1, 0)\n",
    "            num_correct += (x==labels).sum()\n",
    "            total += labels.size(0)\n",
    "        valList.append(val_loss/len(valLoader))\n",
    "        acc_list.append(float(num_correct)/float(total)*100)\n",
    "        print(\"Epoch: {} Training Loss: {} Validation loss: {} LR: {} Accuracy: {}\".format(epoch, epoch_loss/len(trainLoader), val_loss/len(valLoader), optimizer.param_groups[0]['lr'], float(num_correct)/float(total)*100))\n",
    "\n",
    "def trainLBFGS(model, trainLoader, valLoader, optimizer, criterion, tau, epochs, ls_list, valList, acc_list, loss_name= \"sBQC\"):\n",
    "    \"\"\"\n",
    "    Training loop used for LBFGS and conjugate gradient training\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss= 0.0\n",
    "        # training loop\n",
    "        model.train()\n",
    "        for inputs, labels in trainLoader: \n",
    "            inputs= inputs.to(device) \n",
    "            labels= labels.to(device)\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                outputs= model(inputs)\n",
    "                if loss_name== \"BCE\":\n",
    "                    loss= criterion(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "                elif loss_name== \"sBQC\":\n",
    "                    loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "                loss.backward()\n",
    "                return loss\n",
    "            # optimizer.step(closure)\n",
    "            # optimizer.zero_grad() \n",
    "            # outputs= model(inputs) \n",
    "            # loss= criterion(outputs, labels, tau, h) \n",
    "            # loss.backward()\n",
    "            optimizer.step(closure) \n",
    "        # ls_list.append(epoch_loss/len(trainLoader))\n",
    "\n",
    "        # validation loop\n",
    "        val_loss= 0.0\n",
    "        num_correct= 0\n",
    "        total= 0 \n",
    "        model.eval()\n",
    "        for inputs, labels in valLoader:\n",
    "            inputs= inputs.to(device)\n",
    "            labels= labels.to(device)\n",
    "            outputs= model(inputs)\n",
    "            if loss_name== \"BCE\":\n",
    "                loss= criterion(outputs.view(outputs.shape[0],), labels) # For BCE\n",
    "            elif loss_name== \"sBQC\":\n",
    "                loss= criterion(labels, outputs.view(outputs.shape[0],), tau) # For sBQC\n",
    "            val_loss+= loss.item()\n",
    "            x= torch.where(outputs.view(outputs.shape[0]) > 0.5, 1, 0)\n",
    "            num_correct += (x==labels).sum()\n",
    "            total += labels.size(0)\n",
    "        valList.append(val_loss/len(valLoader))\n",
    "        acc_list.append(float(num_correct)/float(total)*100)\n",
    "        print(\"Epoch: {} Training Loss: {} Validation loss: {} Accuracy: {}\".format(epoch, epoch_loss/len(trainLoader), val_loss/len(valLoader),\n",
    "         float(num_correct)/float(total)*100))\n",
    "\n",
    "# def computeLR(model, trainLoader, mask, tau, bSize= 16):\n",
    "#     \"\"\"\n",
    "#     Takes in a network of the LALRnetwork class(during some arbitrary EPOCH of training) and the current input, and returns Kz for the EPOCH\n",
    "#     \"\"\"\n",
    "#     Kz = 0.0\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for i,j in enumerate(trainLoader):\n",
    "#             inputs,labels= j[0],j[1]\n",
    "#             inputs= inputs.to(device)\n",
    "#             labels= labels.to(device)\n",
    "#             op1= model.penU(inputs)\n",
    "#             # first taking the max and min for each batch\n",
    "#             activ1, indx1= torch.max(op1, dim= 1)\n",
    "#             # val1= torch.linalg.norm(op1)\n",
    "#             # now, we take the max and min across batches\n",
    "#             val1, indx2= torch.max(activ1, dim= 0)\n",
    "#             # print(indx, i)\n",
    "#             if val1 > Kz:\n",
    "#                 # in the case of K_z, we do not need the index where the max occurs, hence only deal with the value\n",
    "#                 Kz= val1 \n",
    "#     factor= 1\n",
    "#     if mask == 1:\n",
    "#         factor =  max(2/math.pi, 2-2*tau/(math.pi*tau), 2*tau/(math.pi*(1-tau)))\n",
    "#     else:\n",
    "#         factor= 0.5\n",
    "#     LR= (factor*Kz)/bSize\n",
    "#     # if LR == 0:\n",
    "#     #     return 0.1\n",
    "#     return (1/LR)*0.01\n",
    "\n",
    "def computeLR(model, trainLoader, mask, tau, bSize= 16):\n",
    "    \"\"\"\n",
    "    Takes in a network of the LALRnetwork class(during some arbitrary EPOCH of training) and the current input, and returns Kz for the EPOCH\n",
    "    \"\"\"\n",
    "    Kz = 0.0\n",
    "    # Ka= 0.0\n",
    "    # Y= 0.0\n",
    "    # z_k= 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,j in enumerate(trainLoader):\n",
    "            inputs,labels= j[0],j[1]\n",
    "            inputs= inputs.to(device)\n",
    "            labels= labels.to(device)\n",
    "            op1= model.penU(inputs)\n",
    "            # op2= model(inputs)\n",
    "            # first taking the max and min for each batch\n",
    "            val1= torch.linalg.norm(op1)\n",
    "            # activ1, arg1= torch.max(op1, dim= 1)\n",
    "            # activ2, arg2= torch.min(op2, dim= 1)\n",
    "            # now, we take the max and min across batches\n",
    "            # val1, indx1= torch.max(activ1, dim= 0)\n",
    "            # val2, indx2= torch.min(activ2, dim= 0)\n",
    "            # val3= computeKa(op2)\n",
    "            # val4= computeKa(labels)\n",
    "            if val1 > Kz:\n",
    "                # in the case of K_z, we do not need the index where the max occurs, hence only deal with the value\n",
    "                Kz= val1 \n",
    "            # z_k= val2\n",
    "            # if val3 > Ka:\n",
    "            #     Ka= val3\n",
    "            # if val3 > Y:\n",
    "            #     Y= val4 \n",
    "\n",
    "    LR= 1\n",
    "    factor= 1\n",
    "    if mask== 1: \n",
    "        LR=  max(2/math.pi, 2-2*tau/(math.pi*tau), 2*tau/(math.pi*(1-tau)))*Kz*(1/bSize)\n",
    "        factor= 0.15\n",
    "    else:\n",
    "        LR= 0.5*Kz*(1/bSize)\n",
    "        factor= 0.05\n",
    "\n",
    "    return (1/LR)*factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: -82.61404854910714 Validation loss: -76.59082870483398 LR: 0.2785671651363373 Accuracy: 96.78571428571429\n",
      "Epoch: 1 Training Loss: -82.61404691423688 Validation loss: -76.59082870483398 LR: 0.27856260538101196 Accuracy: 96.78571428571429\n",
      "Epoch: 2 Training Loss: -82.61405181884766 Validation loss: -76.59082870483398 LR: 0.27859219908714294 Accuracy: 96.78571428571429\n",
      "Epoch: 3 Training Loss: -82.61405072893415 Validation loss: -76.59082870483398 LR: 0.2785593569278717 Accuracy: 96.78571428571429\n",
      "Epoch: 4 Training Loss: -82.61405072893415 Validation loss: -76.59082870483398 LR: 0.27857473492622375 Accuracy: 96.78571428571429\n",
      "Epoch: 5 Training Loss: -82.61404800415039 Validation loss: -76.59082870483398 LR: 0.2785775065422058 Accuracy: 96.78571428571429\n",
      "Epoch: 6 Training Loss: -82.61404691423688 Validation loss: -76.59082870483398 LR: 0.27853670716285706 Accuracy: 96.78571428571429\n",
      "Epoch: 7 Training Loss: -82.61404963902065 Validation loss: -76.59082870483398 LR: 0.2785731852054596 Accuracy: 96.78571428571429\n",
      "Epoch: 8 Training Loss: -82.61404854910714 Validation loss: -76.59082870483398 LR: 0.27857527136802673 Accuracy: 96.78571428571429\n",
      "Epoch: 9 Training Loss: -82.61404854910714 Validation loss: -76.59082870483398 LR: 0.27856382727622986 Accuracy: 96.78571428571429\n"
     ]
    }
   ],
   "source": [
    "# LALR, sBQC\n",
    "trainLALR(modelLALR_sBQC, train_loader, test_loader, optimizerLALR_sBQC, criterion, tau, 10, ls_list_LALR_sBQC, val_list_LALR_sBQC, acc_list_LALR_sBQC, 1, \"sBQC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 0.12448933933462415 Validation loss: 0.1374417930841446 LR: 0.2529822289943695 Accuracy: 96.07142857142857\n",
      "Epoch: 1 Training Loss: 0.12648398748465947 Validation loss: 0.13920720666646957 LR: 0.2529822289943695 Accuracy: 96.07142857142857\n",
      "Epoch: 2 Training Loss: 0.14573547882693155 Validation loss: 0.13689088076353073 LR: 0.2529822289943695 Accuracy: 96.07142857142857\n",
      "Epoch: 3 Training Loss: 0.12040134359683309 Validation loss: 0.15340058803558348 LR: 0.2529822289943695 Accuracy: 96.07142857142857\n",
      "Epoch: 4 Training Loss: 0.11276280161525522 Validation loss: 0.14005544334650039 LR: 0.2529822289943695 Accuracy: 96.07142857142857\n",
      "Epoch: 5 Training Loss: 0.1231042854487896 Validation loss: 0.1441948965191841 LR: 0.2529822289943695 Accuracy: 96.07142857142857\n",
      "Epoch: 6 Training Loss: 0.12198963521846704 Validation loss: 0.14046140015125275 LR: 0.2529822289943695 Accuracy: 96.07142857142857\n",
      "Epoch: 7 Training Loss: 0.14312632834272726 Validation loss: 0.14067488461732863 LR: 0.2529822289943695 Accuracy: 96.07142857142857\n",
      "Epoch: 8 Training Loss: 0.12005420641175338 Validation loss: 0.14236827492713927 LR: 0.2529822289943695 Accuracy: 96.07142857142857\n",
      "Epoch: 9 Training Loss: 0.12349935966942992 Validation loss: 0.13689363300800322 LR: 0.2529822289943695 Accuracy: 96.07142857142857\n"
     ]
    }
   ],
   "source": [
    "# LALR, BCE\n",
    "trainLALR(modelLALR_BCE, train_loader, test_loader, optimizerLALR_BCE, criterion_, tau, 10, ls_list_LALR_BCE, val_list_LALR_BCE, acc_list_LALR_BCE, 2, \"BCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: -82.66187776838031 Validation loss: -76.0363983154297 Accuracy: 95.71428571428572\n",
      "Epoch: 1 Training Loss: -82.66593061174665 Validation loss: -76.04040069580078 Accuracy: 95.71428571428572\n",
      "Epoch: 2 Training Loss: -82.66975130353656 Validation loss: -76.04437255859375 Accuracy: 95.71428571428572\n",
      "Epoch: 3 Training Loss: -82.67333439418248 Validation loss: -76.0484405517578 Accuracy: 95.71428571428572\n",
      "Epoch: 4 Training Loss: -82.67677307128906 Validation loss: -76.05205535888672 Accuracy: 95.71428571428572\n",
      "Epoch: 5 Training Loss: -82.68001556396484 Validation loss: -76.05561218261718 Accuracy: 95.71428571428572\n",
      "Epoch: 6 Training Loss: -82.68309075491769 Validation loss: -76.05853576660157 Accuracy: 95.71428571428572\n",
      "Epoch: 7 Training Loss: -82.686037336077 Validation loss: -76.06159591674805 Accuracy: 95.71428571428572\n",
      "Epoch: 8 Training Loss: -82.68882424490792 Validation loss: -76.06456298828125 Accuracy: 95.71428571428572\n",
      "Epoch: 9 Training Loss: -82.69147545950753 Validation loss: -76.06776580810546 Accuracy: 95.71428571428572\n"
     ]
    }
   ],
   "source": [
    "# CLR, sBQC\n",
    "trainConstantLR(modelCLR_sBQC, train_loader, test_loader, optimizerCLR_sBQC, criterion, tau, 10, ls_list_CLR_sBQC, val_list_CLR_sBQC, acc_list_CLR_sBQC, \"sBQC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 0.030538431368768215 Validation loss: 0.16661071367561817 Accuracy: 94.64285714285714\n",
      "Epoch: 1 Training Loss: 0.03177786388966654 Validation loss: 0.1677365081384778 Accuracy: 94.64285714285714\n",
      "Epoch: 2 Training Loss: 0.02984937440071787 Validation loss: 0.16853549033403398 Accuracy: 95.0\n",
      "Epoch: 3 Training Loss: 0.02936616456801338 Validation loss: 0.16690744888037443 Accuracy: 95.0\n",
      "Epoch: 4 Training Loss: 0.029072684501963004 Validation loss: 0.1692367303185165 Accuracy: 95.0\n",
      "Epoch: 5 Training Loss: 0.0284194827212819 Validation loss: 0.1699464414268732 Accuracy: 95.0\n",
      "Epoch: 6 Training Loss: 0.02837654422702534 Validation loss: 0.1717002395540476 Accuracy: 95.0\n",
      "Epoch: 7 Training Loss: 0.029502880327137455 Validation loss: 0.17348455544561148 Accuracy: 95.0\n",
      "Epoch: 8 Training Loss: 0.02577961183020047 Validation loss: 0.17240577144548297 Accuracy: 95.0\n",
      "Epoch: 9 Training Loss: 0.025805150624364614 Validation loss: 0.17249278202652932 Accuracy: 95.0\n"
     ]
    }
   ],
   "source": [
    "# CLR, BCE\n",
    "trainConstantLR(modelCLR_BCE, train_loader, test_loader, optimizerCLR_BCE, criterion_, tau, 10, ls_list_CLR_BCE, val_list_CLR_BCE, acc_list_CLR_BCE, \"BCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 1 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 2 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 3 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 4 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 5 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 6 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 7 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 8 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n",
      "Epoch: 9 Training Loss: 0.0 Validation loss: -67.76021575927734 Accuracy: 81.9672131147541\n"
     ]
    }
   ],
   "source": [
    "# LBFGS, sBQC\n",
    "trainLBFGS(modelLBFGS_sBQC, train_loader, test_loader, optimizerLBFGS_sBQC, criterion, tau, 10, ls_list_LBFGS_sBQC, val_list_LBFGS_sBQC, acc_list_LBFGS_sBQC, \"sBQC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f66262aaac0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzcUlEQVR4nO3de5yddXXo/8/a15k9uTGTBEOSSSBA5BIMEBFoUS5VuSiW9lSI0Cr1HFosR22LB/AoHvvS/jweWxX16KEeRDk0tVigahWwlOqRVjwJBAQi98yQC8kwk0yS2TP7un5/PM+zb/PsPTuZ/ezL7PV+veY1e549e55vhrD2yvp+v+srqooxxpjuEWr1AIwxxjSXBX5jjOkyFviNMabLWOA3xpguY4HfGGO6TKTVA6jH4sWLdfXq1a0ehjHGdJQtW7a8rqpLKq93ROBfvXo1mzdvbvUwjDGmo4jIkN91K/UYY0yXscBvjDFdxgK/McZ0mY6o8RtjgpHJZNixYwdTU1OtHoqZhZ6eHlasWEE0Gq3r+y3wG9PFduzYwfz581m9ejUi0urhmCOgqoyOjrJjxw6OPfbYul5jpR5jutjU1BQDAwMW9DuYiDAwMHBY/2qzwG9Ml7Og3/kO97+hBf42lExn+d6WHTSjZfbBqQz/UONe23Yf4LGXRwMfhzGmeSzwt6Hvb93Fjfc8ycuvTwR+r3sf38mf3/MkL40c8n3+cz/+NR/73lOBj8MY0zwW+NvQ9tEkAIemsk24l/PmMuTes9LQ6AQ790+SyeUDH4vpTvPmzav63Ec+8hGWL19OPl/8+3fnnXdyww03TPve1atXs27dOk477TTe9ra3MTTku2m1pvPPP5+1a9eyfv16TjrpJG6//fbCc+Pj4/zBH/wBa9asYc2aNVx99dXs27ev8Pzzzz/PpZdeyvHHH89JJ53Ee9/7Xvbs2XPYY2gGC/xtaHjMCcbJdC74e7kB3y/wZ3N5duybJJdXdu2fDHwsxpTK5/Pcd999rFy5kp/97Gd1veaRRx7hqaee4vzzz+czn/nMEd337rvvZuvWrTz66KPcdNNNpNNpAD74wQ9y3HHH8dJLL/HSSy9x/PHH84EPfABwJskvu+wyrr/+el588UW2bdvG9ddfz8jIyBGNIWi2nLMNeUE4mQ4+4x8ac+41PDY98O8enyKb18KYVg30BT4e0zqf/sEzPLvrQEN/5snHLOBT7z7liF77yCOPcOqpp3LllVeyadMmzj///Lpfe84553DbbbdVfX5iYoL3vve97Nixg1wuxyc/+UmuvPLKsu85dOgQfX19hMNhXnzxRbZs2cJ3v/vdwvO33nora9as4bnnnuPRRx/lnHPO4d3vfnfh+QsuuKDq/bdv387v//7vMzHhJHlf/epXOffccwH4/Oc/z1133UUoFOKSSy7hc5/7HC+++CJ//Md/zMjICOFwmHvuuYc1a9bU/fuoZIG/zahqIQufCDjjz+e1EPCHRqfPJ5T+K2DI543BmCBt2rSJjRs38p73vIePf/zjZDKZujcoPfDAA/z2b/92zeePOeYY/umf/glwyjieq6++mng8zgsvvMCXvvQlwuEwzz77LOvXryccDhe+LxwOc/rpp7Nt2zaefvppzjzzzLr/bEuXLuUnP/kJPT09vPDCC2zcuJHNmzfz4x//mPvvv5/HHnuMRCLB2NhYYUw333wzV1xxBVNTU2WlryNhgb/N7EtmOJhyMv3JgDP+PQenSGedv0B+gX1orPhmMOzzxmDmliPNzIOQTqf50Y9+xBe/+EXmz5/PW97yFh566CEuu+yymq+74IIL2LNnD0uXLq1Z6lm3bh033ngjN910E+9617s477zzCs/dfffdbNiwgZGREc4991wuvvhiVNV3yeSRrrzLZDLccMMNbN26lXA4zPPPPw/AP//zP3PttdeSSCQA6O/v5+DBg+zcuZMrrrgCcHbpzpbV+NtMaeY9kQo24/cy+lOOWcCOMaeWX2p4NEksEmLNkr6qk7/GBOGBBx5gfHycdevWsXr1an7+85+zadOmGV/3yCOPMDQ0xCmnnMKtt95a9ftOPPFEtmzZwrp167jlllv4i7/4i2nfs2TJEs444wwee+wxTjnlFJ544omyTDufz/PUU09xxhlncMopp7Bly5a6/3xf/OIXOfroo3nyySfZvHlzYR7B7w0miGXdFvjbTGmtPegav1dSOu+EJaRzeV47UL7zb2g0ycqjejl2cZ/vHIAxQdm0aRPf/OY32b59O9u3b+eVV17hoYceIpmc+e9hb28vX/rSl/jOd75TKJVU2rVrF4lEgmuuuYYbb7yRxx9/fNr3JJNJnnjiCdasWcPxxx/P6aefXvaviM985jNcdNFFDA4O8r73vY9/+7d/K5SOwHnz+tWvfuV7//HxcZYtW0YoFOKuu+4il3OSvHe84x3ccccdhT/n2NgYCxYsYMWKFdx///0ApFKpun4PtQQa+EXkT0XkGRF5WkQ2iUiPiPSLyE9E5AX381FBjqHTeJl1SIJf1TM0NkE4JJyzZsC990TF886E7mC/E/ibsaHMdJ9kMsmKFSsKH3/5l3/Jgw8+WFbW6evr4zd/8zf5wQ9+ADhLOktfs2PHjrKfuWzZMjZu3MjXvvY133v+6le/4qyzzmL9+vV89rOf5ROf+EThuauvvpr169dz5pln8oEPfKBQu7/jjjt44YUXOP7441myZAm/+MUv+MY3vgE4bzY//OEP+cpXvsIJJ5zAySefzJ133snSpUt97/+hD32Ib3/725x99tk8//zz9PU5CycuvvhiLr/8cjZs2MD69ev5whe+AMBdd93Fbbfdxmmnnca5557La6+9diS/6gIJ6n9mEVkO/Bw4WVUnReTvgR8BJwNjqvo5EbkZOEpVb6r1szZs2KDdcgLXn//9k/z8xRGmMnmuOH05/+3y4OquN/zt4zy1Y5y7/+NbOO/zj/C531nHVWcNAs4/L0/91IP83oaVHLu4j099/xl++V8vYun82dcXTfvYtm0bJ510UquH0XGee+45Lr30Ur7yla9w6aWXtno4gP9/SxHZoqobKr836MndCNArIhkgAewCbgHOd5//NvCvQM3A302GxyZY1d/Hq/uSgZd6Xh1LMtifYNnCHiIhKZvgHZ1IM5HOMdifYLDfmWgaHk1a4DcGWLt2LS+99FKrh3HEAgv8qrpTRL4ADAOTwEOq+pCIHK2qu93v2S0i/v8W6lJDo0neeuISRidSgS/nHBpLcum6ZUTCIVYc1Vuo+XvjAFg1kGBwIFG4tmF1f6BjMqaRRkdHueiii6Zdf/jhhxkYGAj8/g8++CA33VSe1x577LHcd999gd+7lsACv1u7fw9wLLAfuEdErjmM118HXAcwODgYxBDbzmQ6x96DKVb1J3h+z0GSqeAy/vHJDPuTGVa52fzgQF/58k338aqBBCuO6kXE1vLPVdWWKs4FAwMDbN26tWX3f+c738k73/nOwO9zuCX7ICd3fwt4RVVHVDUD3AucC+wRkWUA7ue9fi9W1dtVdYOqbliyZEmAw2wfr+5zAuvgQILeaDjQyd3hkoweYFV/gqHR4gTu0GgSEVhxVIJ4JMwxC3ttLf8c1NPTw+joqE3cdzDvIJbDWd8fZI1/GDhbRBI4pZ6LgM3ABPB+4HPu538McAwdxSuvDPYn6ItHGDmYCu5ebkY/2O+sJlg1kODgVJbxyQyLEjGGx5K8YUEPPdFwYUyW8c893oqYdu0pY+rjHb1YryBr/I+JyPeAx4Es8ARwOzAP+HsR+SDOm8PvBTWGTuMtp1w10EdvLMxEgJO7hTcZN+P3JnCHRpNO4B9NFq45Y0rwk2fbs9OgOXLRaLTu4/rM3BHoqh5V/RTwqYrLKZzs31QYHksyPx7hqESUvliYyYBLPYvnxZgXd/4KeA3YhsaSvGnlIobGklywtlhiGxxIMDqR5lAqW3iNMaYz2c7dNjI0mmRwIIGIkIhFmAhwcndobKIsoy8u2Zwgmc4ycjBV1o1zlVsSGrbWDcZ0PAv8bWR4LFmYbE3Egp/cLQ3svbEwS+fHGRpNFtozVJZ6nDHaBK8xnc4Cf5vI5ZUd+5KFyda+eIRsXgvdMxsplc2x+8BUWWAHJ7gPjSXL1vB7StfyG2M6mwX+NrFr/ySZnJZl/BBMo7Yd+yZRLQ/s4KzwGR5NFpd69hf/RbCgJ8pRiait7DFmDrDA3ya88oq3ocoL/EHs3q1cw+9ZNZDgtQNTPL/nIAt7oyxMlB96MTjQZzV+Y+YAC/xtonJ5ZSLmrJwJ4jAWb9noYH/5UYreG8GjL74+7U0B3E1eVuM3puNZ4G8Tw2NJomFh2cJeAPribsYfwGEsQ2NJErEwi+fFyq57Nf9d49Pr/+C8MezaP0Um1/h5B2NM81jgbxPDYxOsPCpBOOT0TOmNOhl/EJu4vM1Zlf1Z/JZ3llrZnyCXV3bum2z4mIwxzWOBv014a/g9XsYfxCauobGkb2Dv7yvd0OVf6vFeb4zpXBb424CqOuvqS4JxUJO7+byW7RcoJSKFN4TK+j8Ud/daszZjOltX7b3fN5FGcTLbZttzYIp58Qh9Pu0O9iUzHExlWVkW+KtP7h6YyjCVzrF0QX3d+LbtPsDoIecw5/HJDOlsnsGB6YEdnEz/2d0HfN8Yls6PE4+EeOyVMY5dPK+uextjZufkYxY0PGZ1VeC/8Z4nyeaVb//hWU2/91W3/4J3nHI0t1wy/Zg7r2a+4qiSUo8b+P0md/+/H/2ax4f28eCfvnXG+44eSnHZbf+XfEXX3bVHz/f9/pOXLeAXL4/yBp83lVBIOPHo+fzwqd388KndM97bGDN7d177Zs5f29jzqroq8P/6tYMsqlib3iwjB1NV2yx7m7RKm5/11tjAtWv/JC+OHCKTyxMN167Wvfz6BHmFT1x2Em9aucj52dEwpxyzwPf7r3vbcVx51kpCIf+DOe74wJvZbqUeY5rmxKX+SdpsdE3gT2Vz7BqfpCfammmNqUyOVMZ/GeSU25ahdGyxSIhoWHz79eyfzJDLK7v2T5b12/Hj7Q+48I1LOW7JzOWZeCTM0vnhqs8vmR9nyfz4jD/HGNO+umZy12tTkAqg981Msrk82bySyvpP1KYyznXv0BNPIhbxDfwHJjNAfX1zhkcnCEl5GckY0926JvB7rQamqmTdQfLebKrd2y/jB2dlj19r5v1JZ6K2nmWVQ2NJli3sJRbpmv/UxpgZdE008NoUeNl1M02595yqcm/vejxSmfGHSVa8Jp9Xxt2Mv55llUOj/ks3jTHdq3sCv5sdT1UptwTJy+ir3dt7M4pXZPx98QjJioz/UDpbWKFTV6mnypp9Y0z36prA/6ob+DM5JVe5tjFgXmCvNrmbKpR6yjP+3mh42gau8WSm8Hh4hlLPwakMYxNp381Yxpju1TWBvzQ7rjbJGhSvtl8t4/dKPT0VpZ6+eGRaywavzLOyv5fhsSSq1d/E/A5UMcaYrgj8XpuCuDvB2ewJXi/gV53czeQRgWi4fO18byw8rUmbF/hPW76IZDrHyCH/vQGA7xGKxhjTFYF/78EUqWyeE4521rFXm2QNSj2Tuz2R8LRumX2xMMmKnbv73VLPuhULgWIJy0/hcBfL+I0xJboi8Hsrek502xQ0ey2/d79q901l874by5x1/NUyfifw15rgHRpN0t8XY35Pa3YrG2PaU3cEfjfz9frTNDvj9yZ309k8eZ+J5alMbtrELrjLOStq/PsnnTX8pyxfiEjtwD88NmFlHmPMNF0R+IdHk4RDwrGLndUtzS/1FDN9v6x/KpsvzD+U6otHyOaVdMlrxiczxCIhFvREOGZhb82VPbaG3xjjpysC/9BYkuWLegtN0Jpd6il9o/FbUZSqkfFDeaO28WSGhb3RQu/8oSqbuNLZvNPLxzJ+Y0yFwAK/iKwVka0lHwdE5KMi8iYR+XcR+ZWI/EBE/NtENtDw6ASrBhLE3eDa9FJPyRuN38qeqWy+MLZSfoexjE9mWNTr1OxXDSSqZvw790+SV8p6/BtjDAQY+FX1OVVdr6rrgTOBJHAf8E3gZlVd5379saDG4PGOGvQmUJu+nLPkjcbvTWcqk/Mt9fgdxrLfzfgBBgcSvH4ozSGffj7evwRm6t5pjOk+zSr1XAS8pKpDwFrgZ+71nwC/G+SNxycz7E9mWDWQKJRTWrWBC/w3cVUr9Xjn7pYexjI+mSmcKbCq3zsKcXrWb0s5jTHVNCvwXwVsch8/DVzuPv49YKXfC0TkOhHZLCKbR0ZGjvjGXlAc7O8rZNXVWicEpTTY+907lc3T45Px90bdU7hKa/yTGRaUlHrAWb1TaWg0SU80xFLrnW+MqRB44BeRGE6gv8e99IfAn4jIFmA+kPZ7narerqobVHXDkiVLjvj+Q2NeyaOY8Te7UVtpsK9W6qmV8U9Oq/E7528OuoHfb0nn0KhT3qrcFGaMMc04gesS4HFV3QOgqr8G3gEgIicClwV5c6/kUTrJ2fTlnCVvNFN+yzkz/ss5vRq/N7mbyeU5lMoWavwLeqIsSkR9+/I7a/itvm+Mma4ZpZ6NFMs8iMhS93MI+ATwjSBvPjyaZPG8GPPikUI5pe0md7MzLOd0J2+9k7dKzw1e1Z+YVuNXVWvHbIypKtDALyIJ4O3AvSWXN4rI88CvgV3At4Icg1fyAIiEQ4RD0vTJ3VTWacLmPZ72fMa/ZUOfm/F7u3e9dg1exg8wONBXKGd59h5MMZXJW+A3xvgKNPCralJVB1R1vOTal1X1RPfjZq3VV7gBnMy3WPLoiYSanvGnMjkWuP1yKjN+Va2a8fdWbODa7wX+iox/1/4pMrnin2lo1LpyGmOqm9M7d1PZHLvGJ8sCYE803JKWDV6WXnn0YzqXRxXfGn8sEiIalkKN3z/jT5DLKzv3TRau2Rp+Y0wtczrw79g3iWr5WnYn8De/xl8I/BWlnmqnb3kSseJhLN7pW4t6yzN+KD94fXgsSUhg+aLeBv0JjDFzyZwO/MM+J1DFI6GW1Pi9CdnKf20UDlqvGvjDTLiTu34Zv5fVlx68PjSa5JhFvcR8/hVhjDHNWM7ZMl7Jo3RZY7xFGf+8eC8hmb6iyFvj71fqAbc1s/vm4B3CUhr4l86PE4+EePn1icIb2pDbm8gYY/zM7cA/liQRC7N4XqxwrSfa/Izfm7z1m18onLdbJePvi0cKyznHJzPMi0eIhItvEqGQsHqgj289up1vPbq9cP19bxls8J/CGDNXzOnAf+Ebl7LyqPLdq/FIqPktG9wNWk6ZqUqNv0rG3xsNFyZ390+my7J9z2evOJXHXhkrfC0C7z7tmEYN3xgzx8zpwH/eCUs474Tydg890TBjE75dIgLjNWE70ox/5KBzoPqByYxv4N+wup8Nq/sbPGpjzFzVdbN/PZEWLOfM5olHQ07gr8j4p+qo8XtN2kpbMhtjzJHqvsAfbe4Grrx7dGJPJEw8EjrsjD8RC5NMFdfxl7ZrMMaYI9F1gT8eCTd1cter4cejIeLR8BGt4y/duWsZvzFmtrou8Dc74/feZHoiYbddRLWMv8ZyznQOVWV8MlPWrsEYY45EFwb+5tb4vTcZb3K3smWD17I5Hqk+uZvNKwemsqSzecv4jTGz1nWB3yu3BNwbrqA0o/ddzll4Y6ie8QPsHnd68XiHsBhjzJGaMfCLyG+ISJ/7+BoR+WsRWRX80IJROH7Rpz1yEEozet/lnNmZJ3cBdu13Ar9l/MaY2aon4/86kBSRNwH/BRgCvhPoqAJUOHC9SXX+0ozeb35h5uWczlaLXfunAGxVjzFm1uoJ/Fm3Z/57gC+r6pdxzsrtSF5JpVnn7pYu13TW8ZffN5XJEYuEqp6N652765V6LOM3xsxWPTt3D4rILcA1wFtFJAx0bPTpcSdRmzXBO5UtZvx+7SJS2XzVdg0AvVHnP9FuN+O3wG+Mma16Mv4rgRTwQVV9DVgO/I9ARxWgeLTJNf5MRY0/myubWJ7K+J++5fEy/l1exm+lHmPMLNWV8eOUeHIiciLwRkoOT+80zc74U9nSGn8YVefUrXjJOOJVVvRAsca/e3yKcEiYH5/T7ZWMMU1QT8b/MyAuIsuBh4FrgTuDHFSQvOy6WZu4SjN+bwK39N5TmXzhzchPcTnnFAt6IlXnAowxpl71BH5R1STwO8BXVPUK4JRghxWcnkKpp0kZf8nkrnfKVum9U1UOWvf0uRl/OptnUcLW8BtjZq+uwC8i5wBXA//kXqseqdpcscTSpOWcJb16vEncVGXGX6PU0xsr/qoX2MSuMaYB6gn8HwVuAe5T1WdE5DjgkUBHFaDCcs5mrerJlPTqiU6fX5jK5qq2awCIRUJEw055Z5EFfmNMA8w4U6iqPwV+KiLzRWSeqr4MfDj4oQXDL/gGaSqTJyQQDYvvruFUJs9AX+3330Qs4jRos8BvjGmAelo2rBORJ4CngWdFZIuIdGyNv+ktGzJORi8i1TP+GjV+KE7wWuA3xjRCPaWe/wX8maquUtVB4M+Bv5npRSKyVkS2lnwcEJGPish6EfmFe22ziJw12z/E4Yg3OeNPZYs1fL8VRakZVvVAMfBbuwZjTCPUsyi8T1ULNX1V/VevaVstqvocsB7A3e27E7gP503j06r6YxG5FPg8cP7hD/3I9LRgA5cX8P3mF2Zaxw9Oa2awjN8Y0xj1BP6XReSTwF3u19cArxzmfS4CXlLVIRFRYIF7fSGw6zB/1qzEwiFEmtuywQv83iRuWY0/O3PG3xu1Uo8xpnHqCfx/CHwauBcQnA1d1x7mfa6iuNv3o8CDIvIFnFLTuX4vEJHrgOsABgcHD/N21YmIb1/8oDg1fq/U45/x11rOCZbxG2Maq55VPfuYxSoeEYkBl+MsCQW4HvhTVf0HEXkv8L+B3/K57+3A7QAbNmxo6KkpzTyFK5XNF+YVCjV+dwNXNpcnm9eaG7igtMZvG7iMMbNXNfCLyA+AqgFXVS+v8x6XAI+r6h736/cDH3Ef3wN8s86f0zA9keYF/qlMrrBxq6di85jXubNaL36PreoxxjRSrYz/Cw26x0bKm7rtAt4G/CtwIfBCg+5Tt2YeuJ7K5AqZeryiXURpO4davEZttqrHGNMIVQO/u3FrVkQkAbwd+KOSy/8J+LKIRIAp3Dp+M8Uj4Yb36nng6dd4dvcB/uztJ5Zdn8rkCxl9ZZO20l79tXitmS3jN8Y0QqA9ft3mbgMV134OnBnkfWcSRMb/vS2vsnlo37TAX9qErTCx7Gb6pZ07a7nk1GVEQqEZ/2VgjDH16Mrm7vEAJneHRpOMT2bI55VQqNg6ubIJW+mKotLzeGs5dflCTl2+sKHjNcZ0r3p27s45PdFwQ5dz5vPK8FgSVTiYypY9N1XRdrl0RZG3umemlg3GGNNIM2b87qlbHwNWlX6/ql4Y4LgCFY+EGprx7z2YKryRHKhopla6jh8qAn9J505jjGmWeko99wDfwGm10Jw1kAFrdMY/NDpReLw/mWFlv/NYVd1ePaUZf3F+wSv1zNSywRhjGqmewJ9V1a8HPpIm6mlwxj80liw8Hp/MFB6nc3lUy5drlq4o8j5bxm+MaaZ6Us0fiMiHRGSZiPR7H4GPLECNzviHR4uBf/9kuvDYy+zLSz3FjH+qzsldY4xppHoy/ve7nz9Wck2B4xo/nOZodI1/aCxJbzTMZCZXlvF7yzbjFZO7h9wJ4Kk6N3AZY0wj1dOr59hmDKSZvAlWVUVEZn7BDIZHJzh1+QL+3/Z97E+WBH5vg1akdDlnmNcPOf8qKK7jt4zfGNM89ZzAFRWRD4vI99yPG0Sko7eQ9kRD5BUyucb0fhsaS3Li0fOJRUIcKMn4/TL6eDRUUuPPT3veGGOCVk+q+XWcnbb/0/04073WsYp98Wdf7hmfzLA/mWHVQIJFvdGyjN+3xh8JF1bzFGv8FviNMc1TT43/zar6ppKv/0VEngxqQM1Q7IufZ37P7H7Wq+6KnsH+Phb2Rstr/NnpGb8zuVvcwBUNC+HQ7MtNxhhTr3oy/pyIrPG+EJHj6PD1/I08d3fIXdGzaiDBokR54PfL6J3lnMV1/DP16THGmEarJ+P/GPCIiLyMcwLXKg7/BK624gXiRizpHBpzNm+t7E+wsDfKzv1TheeKNf7K5ZzFjN+Wchpjmq2eVT0Pi8gJwFqcwP9rVU0FPrIAFdsjzz7jHx5NsnhejHnxCAt6o2zbfbDwXKEXT6R8OWc2r2Rzebedg2X8xpjmqnUC14Wq+i8i8jsVT60REVT13oDHFphixt+YUs9gfwKARb0x9ieLG7j8um8W5heyeafUYxm/MabJamX8bwP+BXi3z3OKc/h6R+qpOBBlNobHkpx1rLOReWFvlIl0jkwuTzQcKmT8lTV+cDZ3pbI5a9dgjGm6Widwfcp9+Beq+krpcyLS0Zu6GpXxp7I5do1PFjN+92jE8ckMi+fFi5O7kfJVPeBk/JW9+o0xphnqiTr/4HPte40eSDPFo43J+Hfsm0TVWdEDxaMRvZU9hZ250fK2zN5zU5mcreE3xjRdrRr/G4FTgIUVdf4FwCxXv7eWl4HPdnJ3uGQpJ8BCN+P3NnF5q4biFS0bvHtPZXPM7+nKQ9CMMS1UK+qsBd4FLKK8zn8Q58D0jlXMumeX8Xt9+Af7+4Bixu+1bUi5h7CU9gPysv+UO7lrGb8xptlq1fj/EfhHETlHVf+9iWMKXE8h+M4u4x8aS5KIhVk8LwbAIp9ST2Vg76nI+C3wG2OarZ46wxMi8ic4ZZ9CiUdV/zCwUQWsWG6ZXcY/7C7l9DJ6L+P3lnROZfLTOm8W3nQyNrlrjGmNeqLOXcAbgHcCPwVW4JR7OlajNnANjyUL9X0ondx1+u2nfDL60gZxKdvAZYxpgXoC//Gq+klgQlW/DVwGrAt2WMEKhYRYpLjO/kjk8+oG/r7CtUg4xLx4pHAKl19GX9ogbiprG7iMMc1XT9Txuo7tF5FTgYXA6sBG1CQ9kVBhZ+2R2HswRSqbZ2V/oux6aYdOvxq+9/VkJkc6m7cNXMaYpqunxn+7iBwFfBL4PjAPuDXQUTVBPBqe1eSut6JnlV/gTxYnd6fX+J1A7705WMZvjGm2epq0fdN9+FMO45xdEVkLfLfk0nE4bxjn4CwVBWep6H5VXV/vz22U0kPP/eTzyl2/GOI/nLmCvvj0X9PQWPkafk9pa+ZUNs+8itd6bwTe91jGb4xptlobuP6s1gtV9a9neP45YL37s8LATuA+Vf1SyT3+Chivf7iN0xOpnfFv3bGfT33/GQbmxXjXacdMe37vAaf98rKFvWXXF/ZGeWHvIcCp4w/0+Zd6CoHflnMaY5qsVsY/3/28FngzTpkHnM1cPzvM+1wEvKSqQ94FcdZAvhe48DB/VkM4B65Xz/i9Us5EKuv7/EQ6RywcIlZRyinL+DPT++2HQ0I0LIVykC3nNMY0W60NXJ8GEJGHgDNU9aD79X8D7jnM+1wFbKq4dh6wR1Vf8HuBiFwHXAcwODh4mLebWTwSqrmc0ztZayLl/z3JVJbe2PRsfYE7uauqpLL+J2z1RMKFlT+2nNMY02z1pJuDQLrk6zSHsapHRGLA5Ux/s9jI9DeDAlW9XVU3qOqGJUuW1Hu7ujkZf/XA7/XhSab9M/5kOkefT+Bf1Bsj7XbenPLJ+MGZ0C2WeizjN8Y0Vz2reu4Cfiki9+H04b8C+M5h3OMS4HFV3eNdEJEI8DvAmYfxcxqqJxpiX7JGqWfMC/xVMv50joTPpG9ph85q3TfjkbDV+I0xLVPPqp7PisiPcUozANeq6hOHcQ+/zP63cI5w3HEYP6eh4pHaGf/QaO3AP5HOkvDL+L0OnZNpZ4NWZHpG3xMNsfdgqvDYGGOaqdaqngWqekBE+oHt7of3XL+qjs30w0UkAbwd+KOKp/xq/k0Vr7GccyKV5fVDTmCuVerxC/xexj92KE0ur1Uz/oNT2cJjY4xpploZ/9/itGXeglPi8Yj79Yxr+lU1CQz4XP/AYY0yAD01NnANu2UecFbv+Emmsxw9f/qxBF7g33Nwyr2Pf8bv99gYY5qh1qqed7mfO/qYxWp6IuGqLRu8Mk8kJCSrLOdMpnL0DlTP+F8b90o5Pqt6fM7gNcaYZqlV6jmj1gtV9fHGD6d54tHqTdpedTP+45fOqzm52xfzmdx1a/x73A1e/jX+sO9jY4xphlqlnr+q8ZzSoo1XjdITCZPJKbm8Eg5J2XNDYxMs6IlwzKJeRtxJ2EoTaf91/PPjEcIhYW+h1ONX4y85itFKPcaYJqtV6rmgmQNptmJ75Ny0XjxDo0675d5YmAmfyV1VdTL++PSgLiIs6Imw54DzhuG7gas047dSjzGmyeo66dttx3wy5SdwHc5a/rbjBd9UNk9fvPy54bEkpy5fSF8szKRPqSedy5PLKwmfUg/AokSsUOqpNbkbEoiGZdrzxhgTpBnrDCLyKeAr7scFwOdxduJ2tGqncGVzeXbum2RVf4JELOLbqyfptnHwW84JTtuGvTUyfu9aPBIuO4jdGGOaoZ4C83/AabL2mqpeC7wJiNd+SfvzMv7KwL9r/xTZvLJqIEEiFvad3E26r/Gb3AXn0PV0Lu/ex79lQ7XnjDEmaPVEnklVzQNZEVkA7OUw+vK3q8Kh59nyJZ1DY05XzsH+PvriEbJ5JV3xPd4Sz4RPjR+KSzqd+/g3aav2nDHGBK2ewL9ZRBYBf4Ozmetx4JdBDqoZ4lUyfm8Nv5fxw/Tdu96mrmqlHq9tA9Rex2+B3xjTCrXW8X8V+FtV/ZB76Rsi8gCwQFWfasroAlSs8Zdn88NjSWKREG9Y0FMI7BPpHItKDtry3giqTe6WZvx+6/i9a37PGWNM0Gqt6nkB+CsRWYZzhOImVd3alFE1QaHGn63M+CdYeVQvoZAUAvtkRcbvTe5Wq/HPWOpxr8Ut4zfGtEDVlFNVv6yq5wBvA8aAb4nINhG5VURObNoIA+LV2SvbNnhr+KFYyqk8jMVb2++3gQsqA3/15Zw9lvEbY1pgxsijqkOq+t9V9XTgfTj9+LcFPrKAFSd3i0FdVRkeSzLY79R1vIy/chOXt7bfbwMXOOv4PbU2cFmN3xjTCvWs44+KyLtF5G7gx8DzwO8GPrKA+U3uvn4oTTKdY9WAE/i9wF65ias4uVu71BMNy7R2EGA1fmNMa9Wa3H07ziEql+Gs4vk74DpVnWjS2ALV4zO5O+wu5fQCf+nkbqnCcs4ZVvVUa8dgGb8xppVqTe5+HKcn/431HLrSaYotG4pB3VvKOdjv1fidX09la+ZkJkcsHCIa9s/YvYy/2uRtj23gMsa0UNc2afNbzjk0mkQEVvb3AsVVO5W7d5Mp/86cnkLgr1LKidsGLmNMC3VtyhkJh4iEpKzGPzyWZNmCnkJg7q2ygcvpxV89aPdEw8QjoaoZvXfdavzGmFbo6sjjHL9YWuNPMjhQ3KkVi4SIhmV6xp/OkYjXbmy6sDdaNaO3jN8Y00p1tWWeq3qiIV7ce4gHn3kNgJdHDvGOk99Q9j2JWGRa4J9IZ6tO7HoWJaoHfpvcNca0UlcH/sXz4vz0+RF++vxI4draN8wv+55ELDytNXMynZsx8K8e6CNWpZQzvyfC/HiEZQunH9ZujDFB6+rA/3fXnc3O/ZOFr8Mh4YSl0wN/MlNZ6sly9PzaQfvLV51e9bmeaJif33Qh83q6+tdvjGmRro48ixKxsl22fvrikenLOVM5egdqZ/y1Vv1A8VB2Y4xptq6e3K1HbzQ8fQNXOle1QZsxxrQ7C/wz6ItHfFo2ZKsewmKMMe0usMAvImtFZGvJxwER+aj73H8WkedE5BkR+XxQY2iE3li4rEmbqtY1uWuMMe0qsHqFqj4HrAcQkTCwE7hPRC4A3gOcpqopEVka1BgaoS8WLvTfB0jn8uTyWrVBmzHGtLtmlXouAl5S1SHgeuBzqpoCUNW9TRrDEXHW8Rcz/uIhLJbxG2M6U7MC/1XAJvfxicB5IvKYiPxURN7s9wIRuU5ENovI5pGREb9vaYpELEwynUNVAQpLOy3jN8Z0qsADv4jEgMuBe9xLEeAo4GzgY8Dfi8i0pvWqeruqblDVDUuWLAl6mFX1xSNk80o657R2KLRktsldY0yHakbGfwnwuKrucb/eAdyrjl8CeWBxE8ZxRLxJXG9lT/EQFgv8xpjO1IzAv5FimQfgfuBCAPfs3hjwehPGcUQqD2Px6v1W6jHGdKpAA7+IJIC3A/eWXL4DOE5EnsY51ev96hXQ21DlYSzFyV0L/MaYzhRo9FLVJDBQcS0NXBPkfRvJO3c3WSj1OG8AM7VkMMaYdmU7d2fQG3XeG72A79X6+2xy1xjToSzwz6CQ8acqJ3et1GOM6UwW+GfgTe566/cLyzmt1GOM6VAW+GcwbXI3kyMWDhEN26/OGNOZLHrNwFu9403uJlPWmdMY09ks8M/AW73jrd9PpnMk7KxcY0wHs8A/g1gkRDQsJRu4ciTiNrFrjOlcFvjrkIhFSlo2ZK0zpzGmo1ngr0MiFmYiVSz12OYtY0wns8BfB681Mzi1fmvXYIzpZBb469AXLx7GkkxZjd8Y09ks8NehNxoun9y1VT3GmA5mgb8OpRn/RNrW8RtjOpsF/jqUHr+YTOesXYMxpqNZ4K9DIhYmmcqRzuXJ5dUatBljOpoF/jokYhEm0tmSQ1gs4zfGdC4L/HVIxMJMpnOFnvyW8RtjOpkF/jr0xSNk88r+ZAbAJneNMR3NAn8dvMnc1w+lADtv1xjT2Szw16EY+NOAnbdrjOlsFvjr4NX0Rw5axm+M6XwW+OvgnbvrlXqsxm+M6WQW+OvQG3Uy/ELgt1KPMaaDWeCvg5fxe6UeW85pjOlkFvjr4AV6y/iNMXOBBf46lK7qiYVDRMP2azPGdK7AahYishb4bsml44BbgUXAfwJG3OsfV9UfBTWORvBW8YxNpFmUiLZ4NMYYMzuBBX5VfQ5YDyAiYWAncB9wLfBFVf1CUPdutNJ1+9aL3xjT6ZpVs7gIeElVh5p0v4aKRUJEwwJgp28ZYzpeswL/VcCmkq9vEJGnROQOETnK7wUicp2IbBaRzSMjI37f0lTeBK915jTGdLrAA7+IxIDLgXvcS18H1uCUgXYDf+X3OlW9XVU3qOqGJUuWBD3MGXkTvNauwRjT6ZqR8V8CPK6qewBUdY+q5lQ1D/wNcFYTxjBrXuC3dg3GmE7XjMC/kZIyj4gsK3nuCuDpJoxh1vrc2r7V+I0xnS7QKCYiCeDtwB+VXP68iKwHFNhe8Vzb6nVX89iqHmNMpws08KtqEhiouPb7Qd4zKMWM3wK/Maaz2RbUOlmN3xgzV1jgr5Ot6jHGzBUW+Otk6/iNMXOFBf46ea2ZbVWPMabTWeCvk5fxW0tmY0yns8BfJ5vcNcbMFRb462STu8aYucICf52Kk7uW8RtjOpsF/jq99YQl/NHbjuONy+a3eijGGDMrlr7WaWEiyi2XnNTqYRhjzKxZxm+MMV3GAr8xxnQZC/zGGNNlLPAbY0yXscBvjDFdxgK/McZ0GQv8xhjTZSzwG2NMlxFVbfUYZiQiI8DQEb58MfB6A4fTSO06tnYdF7Tv2Np1XNC+Y2vXcUH7ju1wx7VKVZdUXuyIwD8bIrJZVTe0ehx+2nVs7TouaN+xteu4oH3H1q7jgvYdW6PGZaUeY4zpMhb4jTGmy3RD4L+91QOooV3H1q7jgvYdW7uOC9p3bO06LmjfsTVkXHO+xm+MMaZcN2T8xhhjSljgN8aYLjOnA7+IXCwiz4nIiyJycwvHcYeI7BWRp0uu9YvIT0TkBffzUS0a20oReUREtonIMyLykXYYn4j0iMgvReRJd1yfbodxlYwvLCJPiMgP22xc20XkVyKyVUQ2t9nYFonI90Tk1+7ft3NaPTYRWev+rryPAyLy0VaPq2R8f+r+/X9aRDa5/1/MemxzNvCLSBj4GnAJcDKwUURObtFw7gQurrh2M/Cwqp4APOx+3QpZ4M9V9STgbOBP3N9Tq8eXAi5U1TcB64GLReTsNhiX5yPAtpKv22VcABeo6vqS9d7tMrYvAw+o6huBN+H8/lo6NlV9zv1drQfOBJLAfa0eF4CILAc+DGxQ1VOBMHBVQ8amqnPyAzgHeLDk61uAW1o4ntXA0yVfPwcscx8vA55r9e/MHcs/Am9vp/EBCeBx4C3tMC5ghfs/3IXAD9vpvyewHVhcca3lYwMWAK/gLihpp7GVjOUdwKPtMi5gOfAq0I9zTO4P3THOemxzNuOn+Evz7HCvtYujVXU3gPt5aYvHg4isBk4HHqMNxueWU7YCe4GfqGpbjAv4EvBfgHzJtXYYF4ACD4nIFhG5ro3GdhwwAnzLLZF9U0T62mRsnquATe7jlo9LVXcCXwCGgd3AuKo+1IixzeXALz7XbO1qFSIyD/gH4KOqeqDV4wFQ1Zw6/wRfAZwlIqe2eEiIyLuAvaq6pdVjqeI3VPUMnBLnn4jIW1s9IFcEOAP4uqqeDkzQ2nJYGRGJAZcD97R6LB63dv8e4FjgGKBPRK5pxM+ey4F/B7Cy5OsVwK4WjcXPHhFZBuB+3tuqgYhIFCfo362q97bb+FR1P/CvOPMkrR7XbwCXi8h24O+AC0Xk/7TBuABQ1V3u5704teqz2mRsO4Ad7r/aAL6H80bQDmMD543ycVXd437dDuP6LeAVVR1R1QxwL3BuI8Y2lwP//wNOEJFj3Xfzq4Dvt3hMpb4PvN99/H6c2nrTiYgA/xvYpqp/XfJUS8cnIktEZJH7uBfnf4Jft3pcqnqLqq5Q1dU4f6f+RVWvafW4AESkT0Tme49x6sFPt8PYVPU14FURWeteugh4th3G5tpIscwD7TGuYeBsEUm4/59ehDMhPvuxtWoipUmTI5cCzwMvAf+1hePYhFOjy+BkPh8EBnAmCF9wP/e3aGy/iVMCewrY6n5c2urxAacBT7jjehq41b3eFr83dyznU5zcbfm4cOroT7ofz3h/59thbO441gOb3f+m9wNHtcPYcBYPjAILS661fFzuOD6Nk/A8DdwFxBsxNmvZYIwxXWYul3qMMcb4sMBvjDFdxgK/McZ0GQv8xhjTZSzwG2NMl7HAb7qaiOQqujM2bDepiKyWko6sxrSLSKsHYEyLTarTFsKYrmEZvzE+3L72/909E+CXInK8e32ViDwsIk+5nwfd60eLyH3inB/wpIic6/6osIj8jdtT/SF3FzIi8mERedb9OX/Xoj+m6VIW+E23660o9VxZ8twBVT0L+CpOR07cx99R1dOAu4Hb3Ou3AT9V5/yAM3B2zgKcAHxNVU8B9gO/616/GTjd/Tl/HMwfzRh/tnPXdDUROaSq83yub8c5COZlt4nda6o6ICKv4/RCz7jXd6vqYhEZAVaoaqrkZ6zGaSd9gvv1TUBUVT8jIg8Ah3BaF9yvqocC/qMaU2AZvzHVaZXH1b7HT6rkcY7ivNplOCfEnQlsERGbbzNNY4HfmOquLPn87+7jf8PpyglwNfBz9/HDwPVQOEBmQbUfKiIhYKWqPoJzoMsiYNq/OowJimUZptv1uqd8eR5QVW9JZ1xEHsNJkDa61z4M3CEiH8M5Uepa9/pHgNtF5IM4mf31OB1Z/YSB/yMiC3EODPqiOmcOGNMUVuM3xodb49+gqq+3eizGNJqVeowxpstYxm+MMV3GMn5jjOkyFviNMabLWOA3xpguY4HfGGO6jAV+Y4zpMv8/0pO5ZLnTdgIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# error plots\n",
    "# plt.plot(range(10), ls_list_LALR_sBQC)\n",
    "# plt.plot(range(len(val_list_LALR_sBQC)), val_list_LALR_sBQC, label= \"LALR_sBQC\")\n",
    "# plt.plot(range(len(ls_list_LALR_sBQC)), ls_list_LALR_sBQC, label= \"LALR_sBQC_ls\")\n",
    "# plt.plot(range(len(val_list_CLR_sBQC)), val_list_CLR_sBQC, label= \"CLR_sBQC\")\n",
    "# plt.plot(range(len(val_list_LALR_sBQC)), val_list_LALR_BCE, label= \"LALR_BCE\")\n",
    "# plt.plot(range(len(val_list_CLR_sBQC)), val_list_CLR_BCE, label= \"CLR_BCE\")\n",
    "# plt.plot(range(len(acc_list_CLR_BCE)), acc_list_CLR_BCE, label= \"CLR_BCE_acc\")\n",
    "# plt.plot(range(len(acc_list_CLR_sBQC)), acc_list_CLR_sBQC, label= \"CLR_sBQC_acc\")\n",
    "# plt.plot(range(len(acc_list_LALR_BCE)), acc_list_LALR_BCE, label= \"LALR_BCE_acc\")\n",
    "# plt.plot(range(len(acc_list_LALR_sBQC)), acc_list_LALR_sBQC, label= \"LALR_sBQC_acc\")\n",
    "# plt.plot(range(len(val_list_LBFGS_sBQC)), val_list_LBFGS_sBQC, label= \"LBFGS_sBQC_val\")\n",
    "# plt.plot(range(len(acc_list_LBFGS_sBQC)), acc_list_LBFGS_sBQC, label= \"LBFGS_sBQC_acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# metrics:\n",
    "def computeMetrics(model):\n",
    "    outputs= torch.Tensor([])\n",
    "    outputs= outputs.to(device)\n",
    "    labels= torch.Tensor([])\n",
    "    labels= labels.to(device)\n",
    "    for inputs, label in test_loader:\n",
    "        inputs= inputs.to(device)\n",
    "        label= label.to(device)\n",
    "        output= model(inputs)\n",
    "        outputs= torch.cat((outputs, output))\n",
    "        labels= torch.cat((labels, label))\n",
    "    x= outputs\n",
    "    x= torch.where(outputs.view(outputs.shape[0]) > 0.5, 1, 0)\n",
    "    CP= cohen_kappa_score(labels.detach().to('cpu').numpy(), x.detach().to('cpu').numpy())\n",
    "    JS= jaccard_score(labels.detach().to('cpu').numpy(), x.detach().to('cpu').numpy())\n",
    "    F1= f1_score(labels.detach().to('cpu').numpy(), x.detach().to('cpu').numpy())\n",
    "    return [CP, JS, F1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9154125013731736, 0.8981481481481481, 0.9463414634146342]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeMetrics(modelLALR_BCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "argv": [
    "/home/aryamanj/miniconda3/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "name": "LALRclassification.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
