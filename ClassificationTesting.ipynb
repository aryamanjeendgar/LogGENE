{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code needed to execute the experiments for regular binary Classification datasets, namely misclassification rate and retention rate for deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1caffR-ib-OO",
    "outputId": "f162b9cd-7ee0-438d-cd1c-4c5fc0f0685e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) # Prevents Tanh warning messages \n",
    "\n",
    "Scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFwdfw9scABP"
   },
   "outputs": [],
   "source": [
    "def create_xy(dataset, attribute_columns, target_column, delim, split_ratio,ditch_head=False):\n",
    "    with open(dataset, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    if ditch_head:\n",
    "        lines = lines[1:]\n",
    "    X = []\n",
    "    Y = []\n",
    "    for line in lines:\n",
    "        while len(line) > 0 and line[-1] == \"\\n\":\n",
    "            line = line[:len(line)-1]\n",
    "        split_array = line.split(delim)\n",
    "        all_columns = []\n",
    "        for value in split_array:\n",
    "            if value !=\"\" and value !=\" \":\n",
    "                all_columns.append(value)\n",
    "        if len(all_columns)==0:\n",
    "            break\n",
    "        point = []\n",
    "        for i in attribute_columns:\n",
    "            point.append(float(all_columns[i]))\n",
    "        try:\n",
    "            Y.append(float(all_columns[target_column]))\n",
    "            X.append(point)\n",
    "        except:\n",
    "            pass\n",
    "    X_arr = np.asarray(X)\n",
    "    Scaler.fit(X_arr)\n",
    "    X_arr = Scaler.transform(X_arr)\n",
    "    Y_arr = np.asarray(Y)\n",
    "    thresh = np.median(Y_arr)\n",
    "    Y_arr_binary = np.where(Y_arr<=0,0,1) # Target columns are binary anyway\n",
    "    unique, counts = np.unique(Y_arr_binary, return_counts=True)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_arr, Y_arr_binary, test_size = split_ratio)\n",
    "    return x_train, x_test, y_train, y_test, Y_arr, X_arr, Y_arr_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oDjtcohEcRMh"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(111)\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, indim):\n",
    "        super(Network,self).__init__()\n",
    "        self.l1 = nn.Linear(indim,100)\n",
    "        self.l2 = nn.Linear(100,50)\n",
    "        self.l3 = nn.Linear(50,9)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.l1(x))\n",
    "        x = F.tanh(self.l2(x))\n",
    "        x = self.l3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mxj5vszgcWZH"
   },
   "outputs": [],
   "source": [
    "# Loss and Accuracy Computation functions\n",
    "\n",
    "# def cumLaplaceDistribution(y_pred,mean,standard_deviation,all_qs):\n",
    "#     term1 = ((1-all_qs) * (y_pred - mean))/standard_deviation\n",
    "#     term1.clamp_(max = 0) # Prevents NaN - Only one of term 1 or 2 is used, whichever is -ve\n",
    "#     lesser_term = all_qs * torch.exp(term1)\n",
    "#     term2 = (-1.0 * all_qs * (y_pred - mean))/standard_deviation\n",
    "#     term2.clamp_(max = 0) # Again, Prevents NaN\n",
    "#     greater_term = 1 - ((1-all_qs) * torch.exp(term2))\n",
    "#     mean_tensor = torch.ones_like(mean)\n",
    "#     y_mask = torch.div(y_pred,mean_tensor)\n",
    "#     y_mask[y_pred >= mean] = 1.0\n",
    "#     y_mask[y_pred < mean] = 0.0\n",
    "#     return ((1 - y_mask) * lesser_term )+  (y_mask * greater_term)\n",
    "\n",
    "\n",
    "# def logLikelihoodLoss(y_true,y_pred,mean,standard_deviation,all_qs):\n",
    "#     new_pred = y_pred\n",
    "#     prob = cumLaplaceDistribution(0.0,mean = new_pred,\n",
    "#                                   standard_deviation = standard_deviation,all_qs = all_qs)\n",
    "#     prob.clamp_(min = 1e-7,max = 1 - 1e-7)\n",
    "#     if_one = y_true * torch.log(1 - prob)\n",
    "#     if_zero = (1 - y_true) * torch.log(prob)\n",
    "#     final_loss = - 1 * torch.mean(if_one + if_zero)\n",
    "#     return final_loss\n",
    "\n",
    "# def customLoss(y_true, y_pred, mean, standard_deviation, all_qs, penalty):\n",
    "#     ind_losses = []\n",
    "#     for i,j in enumerate(all_qs):\n",
    "#         single_quantile_loss = logLikelihoodLoss(y_true[:,0],y_pred[:,i] ,\n",
    "#                                                  mean, standard_deviation, j)\n",
    "#         ind_losses.append(single_quantile_loss)\n",
    "#     zero = torch.Tensor([0]).to(device)\n",
    "#     dummy1 = y_pred[:,1:] - y_pred[:,:-1]\n",
    "#     dummy2 = penalty * torch.mean(torch.max(zero,-1.0 * dummy1))\n",
    "#     total_loss  = torch.mean(torch.stack(ind_losses)) +dummy2\n",
    "#     return total_loss\n",
    "\n",
    "def barePDF(x, tau):\n",
    "    \"\"\"\n",
    "    Implements the hyperbolic secant distribution\n",
    "    \"\"\"\n",
    "    # x is a torch tensor, tau is a float\n",
    "    ind= (torch.sign(x)+1)/2 # mask about the origin\n",
    "    quantFactor= (1-tau)*(1-ind) + tau*ind\n",
    "    return 2/math.pi*torch.cosh(x).pow_(-1)*quantFactor\n",
    "\n",
    "def bareCDF(yhat, tau):\n",
    "    \"\"\"\n",
    "    Implements the CDF of the HCD, which is also the required conditional distribution\n",
    "    \"\"\"\n",
    "    # yhat is a torch tensor, tau is a float\n",
    "    ind= (torch.sign(yhat)+1)/2 # mask about the origin\n",
    "    quantFactor= (1-tau)*ind + tau*(1-ind)\n",
    "    val= tau+4*quantFactor/math.pi*torch.atan(torch.tanh(yhat/2))\n",
    "    return val\n",
    "\n",
    "def baresBQR(y, yhat, tau):\n",
    "    \"\"\"\n",
    "    Implements the functional form of the sBQR loss for a specified quantile\n",
    "    \"\"\"\n",
    "    # y and yhat are torch tensors, tau is a float\n",
    "    val= y*torch.log(1-bareCDF(yhat, tau))+(1-y)*torch.log(bareCDF(yhat, tau))\n",
    "    return val\n",
    "\n",
    "def sBQR(y, yhat, qs):\n",
    "    \"\"\"\n",
    "    Returns a list of learnt quantiles for the sBQR loss\n",
    "    \"\"\"\n",
    "    # y and yhat are torch tensors and qs is a list of floats\n",
    "    # yhat would be a [batch,9*outdim] output vector, have to index it accordingly\n",
    "    quantilesBQRs= []\n",
    "    for idx, q in enumerate(qs):\n",
    "        val= baresBQR(y, yhat[:,idx], q)\n",
    "        quantilesBQRs.append(val)\n",
    "    return quantilesBQRs\n",
    "\n",
    "class sBQRL(nn.Module):\n",
    "    \"\"\"\n",
    "    Torch class that implements the loss function\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(sBQRL, self).__init__()\n",
    "    \n",
    "    def forward(self, y, yhat, qs, model, loader):\n",
    "        val= torch.mean(torch.cat(sBQR(y, yhat, qs))) + 0.0025*regularization(qs, model, loader)\n",
    "        return val\n",
    "\n",
    "\n",
    "device= ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\"\"\"\n",
    "Implementation of the loss with the regularization term\n",
    "\"\"\"\n",
    "def regularization(qs, model, loader):\n",
    "    \"\"\"\n",
    "    qs: Quantiles to be learnt\n",
    "    model: Current state of the torch model being trained\n",
    "    loader: The current Torch dataLoader that is being iterated over\n",
    "    \"\"\"\n",
    "    outerSum= 0\n",
    "    for inputs, labels in loader:\n",
    "        inputs= inputs.to(device)\n",
    "        labels= labels.to(device)\n",
    "        outputs= model(inputs) # again, outputs would consist of a [batch, 9*outdim] tensor\n",
    "        innerSum= 0\n",
    "        for idx, q in enumerate(qs):\n",
    "            if idx == len(qs)-1:\n",
    "                break\n",
    "            innerSum+= torch.max(torch.zeros_like(outputs[:,idx]), outputs[:,idx]-outputs[:,idx+1])\n",
    "        outerSum+= torch.sum(innerSum)\n",
    "    print(outerSum)\n",
    "    return outerSum\n",
    "\n",
    "def customTestPred(y_pred,mean,standard_deviation,all_qs,batch_size = 1):\n",
    "    acc = []\n",
    "    cdfs = []\n",
    "    val = (y_pred - mean)/standard_deviation \n",
    "    \n",
    "    for xx in range(batch_size):\n",
    "        if(y_pred < mean[xx]):\n",
    "            lesser_term = all_qs * torch.exp((1.0 - all_qs) * torch.tensor(val[xx], dtype=torch.double)) \n",
    "            # Typecast above needed for some versions of torch\n",
    "            lesser_term  = 1 - lesser_term\n",
    "            cdfs.append(lesser_term.item())\n",
    "            if(lesser_term.item() >= 0.5):\n",
    "                acc.append([1])\n",
    "            else:\n",
    "                acc.append([0])\n",
    "        \n",
    "        elif(y_pred >= mean[xx]):\n",
    "            greater_term = 1.0 - ((1.0-all_qs) * torch.exp(-1.0 * all_qs * torch.tensor(val[xx], dtype=torch.double)))\n",
    "            # Typecast above needed for some versions of torch\n",
    "            greater_term = 1 - greater_term\n",
    "            cdfs.append(greater_term.item())\n",
    "            if(greater_term.item() >= 0.5):\n",
    "                acc.append([1])\n",
    "            else:\n",
    "                acc.append([0])\n",
    "    return torch.Tensor(acc).to(device).reshape(-1,1),torch.Tensor(cdfs).to(device).reshape(-1,1)\n",
    "\n",
    "def acc_tests(test_preds,test_labels):\n",
    "    test_preds = np.array(test_preds).reshape(-1,1)\n",
    "    test_labels = np.array(test_labels).reshape(-1,1)\n",
    "    cdfs_acc,_ = customTestPred(0,test_preds,standard_deviation = 1,all_qs = torch.Tensor([0.5]),\n",
    "                                batch_size = test_preds.shape[0])\n",
    "\n",
    "    count = 0\n",
    "    for i,j in zip(cdfs_acc,test_labels):\n",
    "        if(i.item() == j[0]):\n",
    "            count += 1\n",
    "    return count/test_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing Methods\n",
    "\n",
    "def train(model,loader,epochs, verbose=False):\n",
    "    train_preds_Q = []\n",
    "    train_labels = []\n",
    "    model.train()\n",
    "    \n",
    "    for i,j in enumerate(loader):\n",
    "        inputs,labels = j[0],j[1]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        op_qs = model(inputs)\n",
    "        lossQ = criterion(labels.reshape(-1,1),op_qs, all_qs, model, loader)\n",
    "        lossQ.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        for lag in op_qs[:,4].detach().reshape(-1,1):\n",
    "            train_preds_Q.append(lag.item())\n",
    "        for lag in labels.reshape(-1,1):\n",
    "            train_labels.append(lag.item())\n",
    "            \n",
    "    acc_is_Q = acc_tests(train_preds_Q,train_labels)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"[%d/%d] Train Acc Q : %f \"%(epochs,total_epochs,acc_is_Q))\n",
    "    return acc_is_Q\n",
    "\n",
    "def test(model,loader,epochs,verbose=False):\n",
    "    model.eval()\n",
    "    test_preds_Q = []\n",
    "    test_preds_bce = []\n",
    "    test_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i,j in enumerate(loader):\n",
    "            inputs,labels = j[0],j[1]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            op_qs = model(inputs)\n",
    "            \n",
    "            for lag in op_qs[:,4].detach().reshape(-1,1):\n",
    "                test_preds_Q.append(lag.item())\n",
    "            for lag in labels.reshape(-1,1):\n",
    "                test_labels.append(lag.item())\n",
    "                \n",
    "    acc_is_Q = acc_tests(test_preds_Q,test_labels)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"[%d/%d] Test Acc Q : %f  \"%(epochs,total_epochs,acc_is_Q))\n",
    "    return acc_is_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWB-KbTHciEu"
   },
   "outputs": [],
   "source": [
    "def quantileCDF(x, tau):\n",
    "    if x>0:\n",
    "        return 1 - tau*np.exp((tau-1)*x)\n",
    "    else:\n",
    "        return (1 - tau)*np.exp(tau*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IJA6CBG4cJye",
    "outputId": "ab3e1f00-ce7b-4fd4-fb55-d3ed3eeaa79d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Device: cpu\n"
     ]
    }
   ],
   "source": [
    "batch_is = 64\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion= sBQRL()\n",
    "torch.backends.cudnn.deterministic=True\n",
    "print(\"Torch Device:\",device)\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O6KMY7zwcbvo"
   },
   "outputs": [],
   "source": [
    "# General Control Parameters for the Quantile loss. Need not be changed\n",
    "lr_is = 1e-2\n",
    "mean_is = 0\n",
    "std_is = 1\n",
    "penalty = 1\n",
    "alpha = 0.0\n",
    "\n",
    "# Tau tensor\n",
    "all_qs = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "all_qs = torch.Tensor(all_qs).to(device)\n",
    "all_qs = all_qs.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOROPmdngdkv"
   },
   "outputs": [],
   "source": [
    "# Adjust the dataset details here. Refer the dataset_params.txt file for the specifics of each dataset\n",
    "dataset = './Datasets/Classification/pima.csv'\n",
    "x_cols = list(range(8))\n",
    "y_col = 8\n",
    "separator = \",\"\n",
    "remove_head = True\n",
    "split_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Control Parameters\n",
    "total_runs = 10    # Number of times to run the experiment\n",
    "total_epochs = 20  # No of training epochs per run\n",
    "verbosity = False  # Toggle verbose training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "id": "3D6GEeKWcj_f",
    "outputId": "2d9e06cc-8a4d-4fda-b0ac-c3db86abc9ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "tensor(466.5115, grad_fn=<AddBackward0>)\n",
      "tensor(408.8214, grad_fn=<AddBackward0>)\n",
      "tensor(275.5601, grad_fn=<AddBackward0>)\n",
      "tensor(157.2641, grad_fn=<AddBackward0>)\n",
      "tensor(75.6706, grad_fn=<AddBackward0>)\n",
      "tensor(36.5664, grad_fn=<AddBackward0>)\n",
      "tensor(9.2609, grad_fn=<AddBackward0>)\n",
      "tensor(6.1422, grad_fn=<AddBackward0>)\n",
      "tensor(4.7889, grad_fn=<AddBackward0>)\n",
      "tensor(1.9736, grad_fn=<AddBackward0>)\n",
      "tensor(0.8365, grad_fn=<AddBackward0>)\n",
      "tensor(0.3723, grad_fn=<AddBackward0>)\n",
      "tensor(0.1319, grad_fn=<AddBackward0>)\n",
      "tensor(0.0322, grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "Iteration: 2\n",
      "tensor(609.3043, grad_fn=<AddBackward0>)\n",
      "tensor(464.1716, grad_fn=<AddBackward0>)\n",
      "tensor(338.9126, grad_fn=<AddBackward0>)\n",
      "tensor(152.9377, grad_fn=<AddBackward0>)\n",
      "tensor(116.5460, grad_fn=<AddBackward0>)\n",
      "tensor(93.6931, grad_fn=<AddBackward0>)\n",
      "tensor(54.8019, grad_fn=<AddBackward0>)\n",
      "tensor(19.4550, grad_fn=<AddBackward0>)\n",
      "tensor(10.7915, grad_fn=<AddBackward0>)\n",
      "tensor(9.0312, grad_fn=<AddBackward0>)\n",
      "tensor(7.6109, grad_fn=<AddBackward0>)\n",
      "tensor(3.5982, grad_fn=<AddBackward0>)\n",
      "tensor(1.1184, grad_fn=<AddBackward0>)\n",
      "tensor(0.9264, grad_fn=<AddBackward0>)\n",
      "tensor(0.7670, grad_fn=<AddBackward0>)\n",
      "tensor(0.6396, grad_fn=<AddBackward0>)\n",
      "tensor(0.5106, grad_fn=<AddBackward0>)\n",
      "tensor(0.3331, grad_fn=<AddBackward0>)\n",
      "tensor(0.2164, grad_fn=<AddBackward0>)\n",
      "tensor(0.1203, grad_fn=<AddBackward0>)\n",
      "tensor(0.0238, grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "Iteration: 3\n",
      "tensor(552.1108, grad_fn=<AddBackward0>)\n",
      "tensor(470.9813, grad_fn=<AddBackward0>)\n",
      "tensor(292.2875, grad_fn=<AddBackward0>)\n",
      "tensor(179.2141, grad_fn=<AddBackward0>)\n",
      "tensor(125.8401, grad_fn=<AddBackward0>)\n",
      "tensor(79.3749, grad_fn=<AddBackward0>)\n",
      "tensor(27.1108, grad_fn=<AddBackward0>)\n",
      "tensor(13.9447, grad_fn=<AddBackward0>)\n",
      "tensor(10.3542, grad_fn=<AddBackward0>)\n",
      "tensor(4.5142, grad_fn=<AddBackward0>)\n",
      "tensor(1.3035, grad_fn=<AddBackward0>)\n",
      "tensor(1.0955, grad_fn=<AddBackward0>)\n",
      "tensor(0.4894, grad_fn=<AddBackward0>)\n",
      "tensor(0.1041, grad_fn=<AddBackward0>)\n",
      "tensor(0.0228, grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(0., grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "Iteration: 4\n",
      "tensor(640.2059, grad_fn=<AddBackward0>)\n",
      "tensor(396.4694, grad_fn=<AddBackward0>)\n",
      "tensor(267.3378, grad_fn=<AddBackward0>)\n",
      "tensor(188.3875, grad_fn=<AddBackward0>)\n",
      "tensor(118.8165, grad_fn=<AddBackward0>)\n",
      "tensor(74.0326, grad_fn=<AddBackward0>)\n",
      "tensor(30.3226, grad_fn=<AddBackward0>)\n",
      "tensor(19.8723, grad_fn=<AddBackward0>)\n",
      "tensor(4.4024, grad_fn=<AddBackward0>)\n",
      "tensor(1.4542, grad_fn=<AddBackward0>)\n",
      "tensor(0.9336, grad_fn=<AddBackward0>)\n",
      "tensor(0.6141, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "total_acc = []\n",
    "misc_delta = [[0 for k in range(total_runs)] for i in range(5)]\n",
    "misc_total = [[0 for k in range(total_runs)] for i in range(5)]\n",
    "accept_total = [[0 for k in range(total_runs)] for i in range(5)]\n",
    "\n",
    "data_for_auc = False\n",
    "samples_per_conf_level =[[] for i in range(5)]\n",
    "preds_per_conf_level =[[] for i in range(5)]\n",
    "\n",
    "cov_dataset_generated = False\n",
    "\n",
    "for iter in range(total_runs):\n",
    "    print(\"Iteration:\", iter+1)\n",
    "    \n",
    "    X_train,X_val,y_train,y_val, data_Y, data_X, all_classes = create_xy(dataset, x_cols, y_col, separator, 0.2,remove_head)\n",
    "    X_train = torch.Tensor(X_train)\n",
    "    y_train = torch.Tensor(y_train)\n",
    "    X_val = torch.Tensor(X_val)\n",
    "    y_val = torch.Tensor(y_val)\n",
    "    \n",
    "    train_dataset = data_utils.TensorDataset(X_train, y_train)\n",
    "    test_dataset = data_utils.TensorDataset(X_val, y_val)\n",
    "    train_loader = data_utils.DataLoader(train_dataset, batch_size =128, pin_memory=True,shuffle=True,num_workers = 1)\n",
    "    test_loader = data_utils.DataLoader(test_dataset,batch_size =512,pin_memory=True,shuffle = False,num_workers = 1)\n",
    "    \n",
    "    # This generates the coverage dataset to check the overall delta scores\n",
    "    # Needs to be generated only once\n",
    "    if not cov_dataset_generated:  \n",
    "        X_cov = torch.Tensor(data_X)\n",
    "        y_cov = torch.Tensor(data_Y)\n",
    "        cov_dataset = data_utils.TensorDataset(X_cov, y_cov)\n",
    "        cov_loader = data_utils.DataLoader(cov_dataset, batch_size = 512, pin_memory=True,shuffle=False,num_workers = 1)\n",
    "        cov_dataset_generated = True\n",
    "    \n",
    "    indim = X_train.shape[1]\n",
    "    model = Network(indim)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr_is)\n",
    "    \n",
    "    for epoch in range(total_epochs):\n",
    "        acc_train = train(model,train_loader,epoch, verbosity)\n",
    "        acc_test = test(model,test_loader,epoch,verbosity)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        all_preds = [[] for i in range(9)]\n",
    "        test_labels = []\n",
    "        \n",
    "        for i,j in cov_loader:\n",
    "            inputs,labels = i.to(device),j.to(device)\n",
    "            op_qs = model(inputs)\n",
    "            \n",
    "            for itemset in op_qs.detach():\n",
    "                for quant in range(9):\n",
    "                    all_preds[quant].append(itemset[quant].item())\n",
    "            for lag in labels.reshape(-1,1):\n",
    "                test_labels.append(lag.item())\n",
    "                \n",
    "    delta_total = [0,0,0,0,0]\n",
    "    delta_misc = [0,0,0,0,0]\n",
    "    rms_sum = 0\n",
    "    correct_counter = 0\n",
    "    for i in range(len(data_Y)):\n",
    "        start = 4\n",
    "        left = start\n",
    "        right = start\n",
    "        found = False\n",
    "        count = 0\n",
    "        medprob = quantileCDF(all_preds[start][i], 0.5)\n",
    "        while (left>-1 and not found):\n",
    "            q_left = all_preds[left][i]\n",
    "            q_right = all_preds[right][i]\n",
    "            p_left = quantileCDF(q_left, 0.5)\n",
    "            p_right = quantileCDF(q_right, 0.5)\n",
    "            left -=1\n",
    "            right +=1\n",
    "            if (q_left <= 0.5 and q_right>=0.5):\n",
    "                found = True\n",
    "            else:\n",
    "                count +=1\n",
    "                \n",
    "        delta_total[count-1] +=1\n",
    "        for temp in range(5):\n",
    "            if count-1>=temp:\n",
    "                accept_total[temp][iter] +=1\n",
    "                \n",
    "        if (data_Y[i]==0 and medprob<=0.5) or (data_Y[i]==1 and medprob>0.5):\n",
    "            correct_pred = True\n",
    "            correct_counter += 1\n",
    "        else:\n",
    "            correct_pred = False\n",
    "        if not correct_pred:\n",
    "            delta_misc[count-1] +=1\n",
    "        if not data_for_auc:\n",
    "            samples_per_conf_level[count-1].append(data_Y[i])\n",
    "            preds_per_conf_level[count-1].append(medprob)\n",
    "    \n",
    "    if not data_for_auc:\n",
    "        data_for_auc = True\n",
    "    \n",
    "    total_acc.append(correct_counter/len(data_Y))\n",
    "    for i in range(5):\n",
    "        misc_delta[i][iter] = delta_misc[i]\n",
    "        misc_total[i][iter] = delta_total[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4OraluJCev0l",
    "outputId": "25a23d6f-8751-48a1-fb92-338babbb1b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.00 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : {:.2f} +/- {:.2f}\".format(np.mean(total_acc), np.std(total_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "fVayIz75eGjL",
    "outputId": "0491b70b-403c-4974-82e4-3739224ce044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification vs Delta Results:\n",
      "Delta      |0.10 | 0.20 | 0.30 | 0.40 | 0.50 | \n",
      "Misc. Rate |0.00 | 0.00 | 0.00 | 0.00 | 1.00 | \n",
      "\n",
      "Retention Rate vs Delta Results:\n",
      "Delta      |0.10 | 0.20 | 0.30 | 0.40 | 0.50 | \n",
      "Ret.  Rate |1.00 | 1.00 | 1.00 | 1.00 | 1.00 | \n"
     ]
    }
   ],
   "source": [
    "# Delta based results - Misclassification Rate and Retention Rate\n",
    "\n",
    "misc_rate_results = \"Misc. Rate |\"\n",
    "delta_header      = \"Delta      |\"\n",
    "ret_rate_results  = \"Ret.  Rate |\"\n",
    "\n",
    "for i in range(5):\n",
    "    delta_header += \"{:.2f}\".format(0.1*(i+1)) + \" | \"\n",
    "    total_samples = sum(misc_total[i])\n",
    "    total_misc = sum(misc_delta[i])\n",
    "    v2sum = 0\n",
    "    for j in range(len(misc_total[i])):\n",
    "        if misc_total[i][j] != 0:\n",
    "            v2sum += misc_delta[i][j] /misc_total[i][j] \n",
    "    v2ratio = v2sum/len(misc_total[i])\n",
    "    misc_rate_results += \"{:.2f}\".format(v2ratio) + \" | \"\n",
    "\n",
    "print(\"Misclassification vs Delta Results:\")\n",
    "print(delta_header)\n",
    "print(misc_rate_results)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Retention Rate vs Delta Results:\")\n",
    "print(delta_header)\n",
    "for ret_rate in accept_total:\n",
    "    ret_rate_results += \"{:.2f}\".format(np.mean(ret_rate)/len(data_Y)) + \" | \"\n",
    "print(ret_rate_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_101724/3923070618.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples_per_conf_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples_per_conf_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_per_conf_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0marea_array_roc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfpr_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m     \"\"\"\n\u001b[0;32m--> 962\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    963\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;31m# Filter out zero-weighted samples, as they should not impact the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mallow_nan\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "prec_array = []\n",
    "recall_array = []\n",
    "area_array_pr = []\n",
    "area_array_roc = []\n",
    "conf_array = []\n",
    "fpr_array =[]\n",
    "tpr_array =[]\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    if len(samples_per_conf_level[i])!=0:\n",
    "        fpr, tpr, _ = roc_curve(samples_per_conf_level[i], preds_per_conf_level[i])\n",
    "        area_array_roc.append(auc(fpr, tpr))\n",
    "        fpr_array.append(fpr)\n",
    "        tpr_array.append(tpr)\n",
    "        precision, recall, thresholds = precision_recall_curve(samples_per_conf_level[i], preds_per_conf_level[i])\n",
    "        area_array_pr.append(auc(recall,precision))\n",
    "        prec_array.append(precision)\n",
    "        recall_array.append(recall)\n",
    "        conf_array.append(i+1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Per Confidence Level AUC-ROC Curve\")\n",
    "for i in range(len(area_array_roc)):\n",
    "    plt.plot(fpr_array[i], tpr_array[i], label='Confidence {:.2f} area = {:.2f}'.format(conf_array[i]*0.1, area_array_roc[i]))\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()        \n",
    "        \n",
    "        \n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Per Confidence Level PR Curve\")\n",
    "for i in range(len(area_array_pr)):\n",
    "    plt.plot(recall_array[i], prec_array[i], label='Confidence {:.2f} PR area = {:.2f}'.format(conf_array[i]*0.1, area_array_pr[i]))\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Misc_V_Delta_AdditionalDatasets.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
